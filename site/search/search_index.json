{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"CJK KnowledgeHub","text":"<p>Welcome to the CJK KnowledgeHub \u2014 a living, structured knowledge system for:</p> <ul> <li>Prompt Engineering &amp; AI Engineering</li> <li>IO Persona design (IO-I, IO-II, IO-III)</li> <li>Coursework, projects, and experiments</li> <li>Tools, workflows, and daily notes</li> </ul> <p>Use the navigation on the left to explore projects, persona blueprints, coursework, and your growing knowledge base.</p>"},{"location":"00_Home/","title":"\ud83e\udde0 CJK Knowledge Hub \u2014 Home","text":"<p>Welcome to your central wiki for:</p> <ul> <li>AI career development  </li> <li>prompt engineering  </li> <li>workflow design  </li> <li>IO Persona evolution  </li> <li>coursework integration  </li> <li>knowledge accumulation  </li> </ul> <p>Use this as your entry point into the rest of the system.</p>","tags":["home","overview"]},{"location":"00_Home/#main-areas","title":"Main Areas","text":"<ul> <li>[[../01_Projects/Prompt_Engineering_Portfolio/hub.md|Prompt Engineering Portfolio]]</li> <li>[[../02_IO_Persona/io_overview.md|IO Persona System]]</li> <li>[[../03_Workflows/Prompting/index.md|Workflows \u2014 Prompting]]</li> <li>[[../04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/index.md|Coursework \u2014 Vanderbilt Specialization]]</li> <li>[[../05_Knowledge_Base/Prompt_Patterns/index.md|Knowledge Base \u2014 Prompt Patterns]]</li> <li>[[../06_Tools/Zettlr.md|Tools]]</li> <li>[[../07_Tags/tag_index.md|Tags]]</li> <li>[[../08_Daily_Notes/2025-12-02.md|Daily Notes]]</li> </ul>","tags":["home","overview"]},{"location":"00_Home/instructions/","title":"How to Use This Knowledge Hub","text":"<ol> <li>Start each session at [[index.md]].</li> <li>Log work and reflections in the latest daily note in <code>08_Daily_Notes/</code>.</li> <li>For portfolio work, use:</li> <li>[[../01_Projects/Prompt_Engineering_Portfolio/hub.md|Prompt Engineering Portfolio Hub]]</li> <li>For IO persona evolution, use:</li> <li>[[../02_IO_Persona/io_overview.md|IO Persona Overview]]</li> <li>For coursework, use:</li> <li>[[../04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/index.md]]</li> </ol> <p>This hub is designed to evolve with your workflow and portfolio.</p>","tags":["instructions","meta"]},{"location":"00_Home/structure/","title":"Structure Overview","text":"","tags":["structure","meta"]},{"location":"00_Home/structure/#00_home","title":"00_Home","text":"<p>Entry point, structure documentation, usage instructions.</p>","tags":["structure","meta"]},{"location":"00_Home/structure/#01_projects","title":"01_Projects","text":"<p>Active projects (portfolio, case studies, conversational AI, infrastructure).</p>","tags":["structure","meta"]},{"location":"00_Home/structure/#02_io_persona","title":"02_IO_Persona","text":"<p>All IO persona generations (IO-I, IO-II, IO-III), blueprints and notes.</p>","tags":["structure","meta"]},{"location":"00_Home/structure/#03_workflows","title":"03_Workflows","text":"<p>Prompting, evaluation, research, code, and creative workflows.</p>","tags":["structure","meta"]},{"location":"00_Home/structure/#04_coursework","title":"04_Coursework","text":"<p>Vanderbilt Prompt Engineering Specialization, Google IT Automation with Python, IBM GenAI, certificates.</p>","tags":["structure","meta"]},{"location":"00_Home/structure/#05_knowledge_base","title":"05_Knowledge_Base","text":"<p>Prompt patterns, AI concepts, safety &amp; ethics, glossary, reading notes.</p>","tags":["structure","meta"]},{"location":"00_Home/structure/#06_tools","title":"06_Tools","text":"<p>Usage notes for Zettlr, GitHub, JupyterLab, marimo, VS Code, Nextcloud, Linux.</p>","tags":["structure","meta"]},{"location":"00_Home/structure/#07_tags","title":"07_Tags","text":"<p>Tag index and conventions.</p>","tags":["structure","meta"]},{"location":"00_Home/structure/#08_daily_notes","title":"08_Daily_Notes","text":"<p>Date-based notes for logging work, reflections, and tasks.</p>","tags":["structure","meta"]},{"location":"01_Projects/Case_Studies/","title":"Case Studies \u2014 Index","text":"<p>List and link your case studies here.</p>","tags":["case-study","portfolio"]},{"location":"01_Projects/Conversational_AI/hub/","title":"Conversational AI \u2014 Project Hub","text":"<p>Placeholder hub for future conversational and interaction design projects.</p>","tags":["conversational-ai","portfolio"]},{"location":"01_Projects/Portfolio_Infrastructure/hub/","title":"Portfolio Infrastructure \u2014 Project Hub","text":"<p>Notes and decisions about how your GitHub, wiki, and tools are organized.</p>","tags":["portfolio","infrastructure"]},{"location":"01_Projects/Prompt_Engineering_Portfolio/backlog/","title":"Backlog \u2014 Prompt Engineering Portfolio","text":"","tags":["portfolio","backlog"]},{"location":"01_Projects/Prompt_Engineering_Portfolio/backlog/#ready","title":"Ready","text":"<ul> <li>[ ] Create GitHub repo <code>prompt-engineering-portfolio</code></li> <li>[ ] Define repo README structure</li> <li>[ ] Draft 5\u201310 core prompt templates</li> <li>[ ] Sketch first workflow (content generation)</li> <li>[ ] Sketch first evaluation notebook</li> </ul>","tags":["portfolio","backlog"]},{"location":"01_Projects/Prompt_Engineering_Portfolio/backlog/#in-progress","title":"In Progress","text":"<ul> <li>[ ] </li> </ul>","tags":["portfolio","backlog"]},{"location":"01_Projects/Prompt_Engineering_Portfolio/backlog/#done","title":"Done","text":"<ul> <li>[x] Define project hub and backlog</li> </ul>","tags":["portfolio","backlog"]},{"location":"01_Projects/Prompt_Engineering_Portfolio/decisions/","title":"Decision Log \u2014 Prompt Engineering Portfolio","text":"<p>Record key decisions here.</p>","tags":["portfolio","decisions"]},{"location":"01_Projects/Prompt_Engineering_Portfolio/decisions/#decisions","title":"Decisions","text":"<ul> <li>2025-12-02 \u2014 Use <code>prompt-engineering-portfolio</code> as flagship GitHub repo name.</li> <li>2025-12-02 \u2014 Structure portfolio around prompt library, workflows, evaluation, and case studies.</li> </ul>","tags":["portfolio","decisions"]},{"location":"01_Projects/Prompt_Engineering_Portfolio/hub/","title":"Prompt Engineering Portfolio \u2014 Project Hub","text":"<p>This project defines and tracks the creation of your flagship prompt engineering portfolio.</p>","tags":["portfolio","prompt-engineering"]},{"location":"01_Projects/Prompt_Engineering_Portfolio/hub/#goals","title":"Goals","text":"<ul> <li>Demonstrate professional-level prompt engineering.</li> <li>Showcase workflows, evaluation, and persona design.</li> <li>Align with target roles: Prompt Engineer, AI Workflow Designer, AI QA, Conversational AI Designer.</li> </ul>","tags":["portfolio","prompt-engineering"]},{"location":"01_Projects/Prompt_Engineering_Portfolio/hub/#sections","title":"Sections","text":"<ul> <li>[[backlog.md|Backlog &amp; Tasks]]</li> <li>[[decisions.md|Decision Log]]</li> <li>[[workflow_notes.md|Workflow Notes]]</li> <li>drafts/ \u2014 rough drafts for case studies and README content.</li> </ul>","tags":["portfolio","prompt-engineering"]},{"location":"01_Projects/Prompt_Engineering_Portfolio/workflow_notes/","title":"Workflow Notes \u2014 Prompt Engineering Portfolio","text":"<p>Use this file to sketch and refine workflows before turning them into formal documentation or notebooks.</p> <ul> <li>Link to final workflows in <code>03_Workflows/</code>.</li> </ul>","tags":["portfolio","workflow"]},{"location":"02_IO_Persona/io_overview/","title":"IO Persona System \u2014 Overview","text":"<p>This section tracks IO-I, IO-II, and IO-III persona generations, versions, and evolution.</p>","tags":["io-persona","overview"]},{"location":"02_IO_Persona/io_overview/#generations","title":"Generations","text":"<ul> <li>[[IO-I/notes.md|IO-I]]</li> <li>[[IO-II/notes.md|IO-II]]</li> <li>[[IO-III/roadmap.md|IO-III]]</li> </ul>","tags":["io-persona","overview"]},{"location":"02_IO_Persona/IO-I/notes/","title":"IO-I \u2014 Notes","text":"<p>High-level notes about IO-I persona design and behavior.</p>","tags":["io-persona","io-i"]},{"location":"02_IO_Persona/IO-II/notes/","title":"IO-II \u2014 Notes","text":"<p>High-level notes about IO-II persona evolution and versions.</p>","tags":["io-persona","io-ii"]},{"location":"02_IO_Persona/IO-III/roadmap/","title":"IO-III \u2014 Roadmap","text":"<p>High-level ideas and milestones for IO-III as a multi-agent, sensor-integrated system.</p>","tags":["io-persona","io-iii"]},{"location":"02_IO_Persona/experiments/scratchpad/","title":"IO Persona \u2014 Experiments Scratchpad","text":"<p>Use this for quick persona-related experiments before formalizing changes.</p>","tags":["io-persona","experiments"]},{"location":"03_Workflows/Code_Notebooks/","title":"Workflows \u2014 Code &amp; Notebooks","text":"<p>Index of workflows involving JupyterLab, marimo, and Python for evaluation or automation.</p>","tags":["workflow","notebooks"]},{"location":"03_Workflows/Creative/","title":"Workflows \u2014 Creative","text":"<p>Index of creative workflows (e.g., narrative design, interactive experiences, scripts, content design).</p>","tags":["workflow","creative"]},{"location":"03_Workflows/Evaluation/","title":"Workflows \u2014 Evaluation","text":"<p>Index of workflows for testing prompts, measuring quality, and detecting hallucinations.</p>","tags":["workflow","evaluation"]},{"location":"03_Workflows/Prompting/","title":"Workflows \u2014 Prompting","text":"<p>Index of prompting workflows (e.g., content generation, research assistant, evaluation prompts).</p>","tags":["workflow","prompt-engineering"]},{"location":"03_Workflows/Research/","title":"Workflows \u2014 Research","text":"<p>Index of workflows for research, long-doc analysis, and structured reading.</p>","tags":["workflow","research"]},{"location":"04_Coursework/Certificates/","title":"Certificates \u2014 Index","text":"<p>List your earned certificates and relevant details here.</p>","tags":["certificates"]},{"location":"04_Coursework/Google_IT_Automation_with_Python/","title":"Google IT Automation with Python \u2014 Index","text":"<p>Use this folder for your notes and module summaries.</p>","tags":["coursework","google","python"]},{"location":"04_Coursework/IBM_Generative_AI_Engineering_Professional_Certificate/","title":"IBM Generative AI Engineering Professional Certificate \u2014 Index","text":"<p>Use this folder for IBM course notes and integration with your portfolio.</p>","tags":["coursework","ibm","generative-ai"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/","title":"Prompt Engineering Specialization \u2014 Notes Portal","text":"<p>This site is a lightweight view of my structured notes.</p> <p>Full repository: https://github.com/CevenJKnowles/prompt-engineering-specialization</p>","tags":["PromptEngineering","AIEngineering","course_unknown","module_0","index","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/","title":"Graded Assignment 1","text":"","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#creating-your-first-prompts","title":"Creating Your First Prompts","text":"","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#1-create-a-prompt-for-a-large-language-model-such-as-chatgpt-to-describe-how-large-language-models-work-ask-at-least-three-follow-up-questions-based-on-the-output-provide-the-prompts-and-outputs-from-the-conversation-as-the-answer","title":"1. Create a prompt for a large language model, such as ChatGPT, to describe how large language models work. Ask at least three follow-up questions based on the output. Provide the prompts and outputs from the conversation as the answer.","text":"","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#answer","title":"Answer","text":"<p>Me: Can you summarise in one paragraph how large language models work?</p> <p>ChatGPT: Large language models learn statistical patterns in text by training on enormous datasets, adjusting billions of internal parameters to predict the next token in a sequence. Through this repeated prediction process, they build a layered internal representation of grammar, semantics, reasoning patterns, factual associations, and even task structures. At runtime, the model takes an input prompt, encodes it into vectors, and then generates tokens one by one\u2014each step influenced by both the prompt and its learned internal patterns\u2014allowing it to produce coherent responses, follow instructions, or solve problems without explicit programming.</p> <p>Me: Is this the same across all LLMs?</p> <p>ChatGPT: Broadly yes\u2014but with meaningful variations.</p> <p>Almost all LLMs share the same core principle: they learn by predicting the next token and adjusting internal parameters to capture patterns in language. This predictive-learning architecture (the Transformer) is the common foundation behind GPT, Claude, Gemini, LLaMA, Mistral, and most modern open-source models.</p> <p>However, they differ in important ways:</p> <ul> <li>Training data: size, diversity, quality, and recency vary widely.</li> <li>Model size and architecture tweaks: some use standard Transformers, others use mixtures-of-experts (MoE), rotary positional embeddings, or optimized attention mechanisms.</li> <li>Fine-tuning strategy: instruction tuning, reinforcement learning from human feedback (RLHF), preference optimization (DPO), or domain-specialized training can change the model\u2019s style and capabilities.</li> <li>Inference techniques: sampling strategies, caching, parallelism, and quantization differ across model families.</li> </ul> <p>So the fundamental mechanism is shared, but the capabilities, behavior, and efficiency can differ substantially depending on these design choices.</p> <p>Me: What are the differences between Transformers, MoE, rotary positional embeddings, and optimized attention mechanisms?</p> <p>ChatGPT: Here\u2019s a clean, high-resolution breakdown of the four concepts and how they differ:</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#1-transformers-the-overall-architecture","title":"1. Transformers (the overall architecture)","text":"<p>What they are:\\ The core neural architecture behind almost all modern LLMs.</p> <p>Key idea:\\ Transformers use self-attention to let every token look at every other token in the input, learning relationships across a sequence without relying on recurrence (RNNs) or convolution (CNNs).</p> <p>Why it matters:\\ This architecture scales extremely well and captures long-range dependencies in language.</p> <p>Think of it as:\\ The entire building\u2014all other items below are components or upgrades inside that building.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#2-mixture-of-experts-moe","title":"2. Mixture-of-Experts (MoE)","text":"<p>What it is:\\ A scaling technique where the model contains multiple \u201cexpert\u201d subnetworks, but only a small subset is activated per token using a gating network.</p> <p>Key idea:\\ Instead of making one huge dense model, MoE spreads capacity across many experts while keeping compute low at inference.</p> <p>Why it matters:</p> <ul> <li> <p>Higher capacity without proportional compute cost</p> </li> <li> <p>More specialization: different experts may handle different linguistic or reasoning patterns</p> </li> </ul> <p>Think of it as:\\ A neighborhood of specialists where only the right experts wake up depending on the token.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#3-rotary-positional-embeddings-rope","title":"3. Rotary Positional Embeddings (RoPE)","text":"<p>What they are:\\ A method for encoding token order into the model using rotations in a continuous vector space.</p> <p>Key idea:\\ Transformers need position info. RoPE does this efficiently and allows extrapolation to longer contexts better than older positional systems.</p> <p>Why it matters:</p> <ul> <li> <p>Enables long context windows (many current LLMs use RoPE extensions)</p> </li> <li> <p>More stable and smoother positional encoding than sinusoidal alternatives</p> </li> </ul> <p>Think of it as:\\ A mathematical compass that helps the model understand sequence order and distance.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#4-optimized-attention-mechanisms","title":"4. Optimized Attention Mechanisms","text":"<p>What they are:\\ A general category describing any improvement that makes attention faster, cheaper, or more memory-efficient.</p> <p>Examples:</p> <ul> <li> <p>FlashAttention (faster, memory-efficient exact attention)</p> </li> <li> <p>Multi-Query Attention (Mistral, GPT-4)\u2014reduces memory by sharing key/value projections</p> </li> <li> <p>Linear attention variants (for extreme long contexts)</p> </li> <li> <p>Sliding-window or blockwise attention (Gemini, Claude optimizations)</p> </li> </ul> <p>Key idea:\\ Standard attention scales with O(n\u00b2) memory/time. Optimizations reduce that cost so models can handle longer inputs or run faster.</p> <p>Why it matters:</p> <ul> <li> <p>Enables 100k\u20131M token contexts</p> </li> <li> <p>Reduces GPU requirements</p> </li> <li> <p>Improves latency</p> </li> </ul> <p>Think of it as:\\ Upgrading the engine of the Transformer so it can handle more data with less fuel.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#how-they-relate","title":"How they relate","text":"<ul> <li> <p>Transformer = the base architecture.</p> </li> <li> <p>Rotary positional embeddings = how positions are encoded inside the Transformer.</p> </li> <li> <p>Optimized attention = ways to compute attention more efficiently within the Transformer.</p> </li> <li> <p>MoE = a way to scale the Transformer by adding many specialized expert modules.</p> </li> </ul> <p>They are not competing concepts\u2014they are layers of evolution that can coexist in a single model.</p> <p>If you'd like, I can also map each method to real models (GPT-4/5, Claude, Gemini, LLaMA, Mistral), or build you a visual diagram summarizing how these components interact.</p> <p>Me: Could you give me a list of the top 5 major LLMs and which types of architecture they use?</p> <p>ChatGPT: Here\u2019s a breakdown of five major large-language-models (LLMs) and the architectures they use:</p> <p>Model   Developer   Architecture type GPT\u20114   OpenAI  Dense decoder-only Transformer (standard Transformer architecture)  newsletter.semianalysis.com +2 kafkai.com +2</p> <p>PaLM (~540B)    Google AI   Dense decoder-only Transformer (no public large-scale MoE disclosed for that version)  Wikipedia +1</p> <p>Gemini 1.5  DeepMind / Google   Transformer + Mixture-of-Experts (MoE) architecture (\u201cexpert\u201d subnetworks selectively activated)  blog.google +1</p> <p>LLaMA 4 (the latest by Meta AI) Meta AI Mixture-of-Experts (MoE) variant of the Transformer architecture (sparse routing)  AI Meta +2 Wikipedia +2</p> <p>Mixtral 8\u00d77B (open-source)  Mistral AI  Sparse mixture-of-experts Transformer: at each layer a router picks a subset of expert feed-forward networks.  arxiv.org +1</p> <p>If you like, I can extend this list to the top 10 models and include architecture details (dense vs sparse, long-context window, expert count, etc.).</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#2-create-a-prompt-for-a-large-language-model-such-as-chatgpt-that-asks-it-to-perform-an-instruction-other-than-answering-a-question-for-example-ask-chatgpt-to-create-a-meal-plan-plan-a-trip-create-a-recipe-or-help-you-diagnose-a-problem-provide-the-prompts-and-outputs-from-the-conversation-as-the-answer","title":"2. Create a prompt for a large language model, such as ChatGPT, that asks it to perform an instruction other than answering a question. For example, ask ChatGPT to create a meal plan, plan a trip, create a recipe, or help you diagnose a problem. Provide the prompts and outputs from the conversation as the answer.","text":"","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#answer_1","title":"Answer","text":"<p>Me: Can you tell me how to make the perfect espresso?</p> <p>ChatGPT: Absolutely \u2014 here\u2019s the distilled, no-nonsense version of how to pull a perfect espresso, based on what top baristas agree on. This is practical, reproducible, and tuned for taste clarity and consistency.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#the-perfect-espresso-the-core-formula","title":"The Perfect Espresso: The Core Formula","text":"","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#1-dose-the-coffee-amount","title":"1. Dose (the coffee amount)","text":"<ul> <li> <p>18\u201320 g of high-quality, freshly roasted beans</p> </li> <li> <p>Grind fresh and fine (about table-salt fine)</p> </li> <li> <p>Espresso is extremely sensitive to grind size \u2014 this is your main control dial.</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#2-distribution-tamping","title":"2. Distribution &amp; Tamping","text":"<ul> <li> <p>Shake or tap the portafilter to level the grounds</p> </li> <li> <p>Tamp with:</p> </li> <li> <p>~15\u201320 kg of pressure</p> </li> <li> <p>Perfectly even (the levelness matters more than the strength)</p> </li> </ul> <p>Goal: a uniform coffee bed that water passes through evenly.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#3-brew-ratio","title":"3. Brew Ratio","text":"<p>The gold standard:</p> <p>1:2 ratio\\ (For 18 g in \u2192 36 g out)</p> <p>This defines the balance between sweetness, acidity, and bitterness.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#4-brew-time","title":"4. Brew Time","text":"<ul> <li> <p>25\u201330 seconds, starting the moment you hit the button</p> </li> <li> <p>If it runs too fast \u2192 grind finer</p> </li> <li> <p>Too slow \u2192 grind coarser</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#5-water","title":"5. Water","text":"<ul> <li> <p>Temperature: 92\u201396\u00b0C</p> </li> <li> <p>Clean, filtered water with balanced minerals (not distilled)</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#6-shot-appearance","title":"6. Shot Appearance","text":"<p>Look for:</p> <ul> <li> <p>Steady, thick \u201cmouse tail\u201d stream</p> </li> <li> <p>Rich, even crema</p> </li> <li> <p>No blonding until the very end (pale yellow = extraction is done)</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#taste-calibration-the-secret","title":"Taste Calibration (the secret)","text":"<p>If the shot tastes sour \u2192 under-extracted \u2192 grind finer\\ If the shot tastes bitter \u2192 over-extracted \u2192 grind coarser\\ If the shot tastes hollow/thin \u2192 increase dose or reduce output\\ If the shot tastes muddy/overwhelming \u2192 decrease dose or increase output</p> <p>This is the real artistry.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#what-perfect-tastes-like","title":"What Perfect Tastes Like","text":"<p>A great espresso should be:</p> <ul> <li> <p>Sweet first</p> </li> <li> <p>Structured acidity</p> </li> <li> <p>Balanced bitterness</p> </li> <li> <p>Thick, syrupy mouthfeel</p> </li> <li> <p>Long, pleasant finish</p> </li> </ul> <p>Even a dark roast should still have clarity, not harshness.</p> <p>If you want, I can:</p> <ul> <li> <p>Give you a step-by-step ritual customized for your machine (manual, semi-auto, or fully automatic)</p> </li> <li> <p>Optimize for specific beans (light vs. dark roast)</p> </li> <li> <p>Help you troubleshoot crema, channeling, watery shots, bitter shots\u2014anything</p> </li> </ul> <p>Just tell me your setup and what beans you use.</p> <p>Me: Can you tell me the right way if I am using a Delonghi Magnifica S full automat machine with Edeka Bio Esspresso beans?</p> <p>ChatGPT: Absolutely \u2014 with a De\u2019Longhi Magnifica S and Edeka Bio Espresso beans, \u201cperfect espresso\u201d means optimising the machine\u2019s limited controls rather than chasing caf\u00e9-grade precision. Here\u2019s the right way to get the absolute best out of this specific setup.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#1-set-your-grinder-correctly-the-most-important-step","title":"1. Set Your Grinder Correctly (the most important step)","text":"<p>The Magnifica S has a built-in burr grinder with fixed steps.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#optimal-range-for-espresso","title":"Optimal range for espresso:","text":"<p>Setting 2\u20133 (counting from the finest side)</p> <p>How to adjust correctly:</p> <ul> <li> <p>Only change the grinder while the machine is grinding (to avoid damage).</p> </li> <li> <p>Reduce one step at a time \u2192 run 2\u20133 shots \u2192 taste \u2192 adjust again.</p> </li> </ul> <p>Why:\\ These machines grind a bit coarser than caf\u00e9 grinders, so you compensate by using the machine\u2019s lowest feasible grind setting.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#2-aroma-strength-setting","title":"2. Aroma (Strength) Setting","text":"<p>Use 2 or 3 beans (medium-high strength).</p> <p>This tells the machine to dose more coffee, which is crucial because automatic machines underdose by default.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#3-amount-of-water-the-espresso-volume","title":"3. Amount of Water (the espresso volume)","text":"<p>Set the espresso button to 30\u201335 ml.</p> <p>On a super-automatic machine, controlling volume is how you approximate the correct 1:2 ratio.</p> <ul> <li> <p>Less water = richer, sweeter, more syrupy</p> </li> <li> <p>More water = thinner, bitter</p> </li> </ul> <p>30\u201335 ml is the sweet spot.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#4-temperature-setting","title":"4. Temperature Setting","text":"<p>Set to HIGH.</p> <p>Why:\\ Automatic machines lose heat faster than commercial machines. High temp brings out sweetness and reduces sourness, especially with organic beans.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#5-beans-edeka-bio-espresso","title":"5. Beans: Edeka Bio Espresso","text":"<p>These beans are:</p> <ul> <li> <p>Medium-dark, a bit oily</p> </li> <li> <p>Designed for fully automatics</p> </li> <li> <p>Naturally chocolatey, mild, low acidity</p> </li> </ul> <p>What this means for tuning:</p> <ul> <li> <p>Finer grind works well</p> </li> <li> <p>Higher temperature is ideal</p> </li> <li> <p>Keep the espresso short (don\u2019t pull 60 ml singles \u2014 they go bitter fast)</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#6-maintenance-that-affects-taste","title":"6. Maintenance That Affects Taste","text":"<p>This is not optional \u2014 these machines are extremely sensitive:</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#weekly","title":"Weekly:","text":"<ul> <li> <p>Rinse brew group</p> </li> <li> <p>Clean coffee oil buildup from the chute</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#monthly","title":"Monthly:","text":"<ul> <li> <p>Use descaler</p> </li> <li> <p>Clean the grinder hopper</p> </li> <li> <p>Empty dredge + drip tray</p> </li> </ul> <p>Dirty machines = bitter, hollow, and inconsistent espresso.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#7-the-flavour-targets-for-this-setup","title":"7. The Flavour Targets for This Setup","text":"<p>With this machine + these beans, the \u201cperfect\u201d shot should taste:</p> <ul> <li> <p>Smooth</p> </li> <li> <p>Low acidity</p> </li> <li> <p>Mild bitterness, but not burnt</p> </li> <li> <p>Chocolatey with a slight nutty finish</p> </li> <li> <p>Medium body (Magnifica S can\u2019t produce caf\u00e9-level thickness)</p> </li> </ul> <p>If it tastes sour \u2192 grind finer or raise water temp\\ If it tastes bitter \u2192 grind coarser or reduce volume to 25\u201330 ml\\ If it tastes weak \u2192 increase aroma strength and reduce water volume\\ If it tastes burnt \u2192 reduce temperature to medium (rarely needed for this bean)</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#your-ideal-settings-summary","title":"Your Ideal Settings Summary","text":"<p>For De\u2019Longhi Magnifica S + Edeka Bio Espresso beans:</p> <ul> <li> <p>Grind: 2\u20133 (fine)</p> </li> <li> <p>Aroma strength: 2\u20133 beans</p> </li> <li> <p>Water volume: 30\u201335 ml</p> </li> <li> <p>Temperature: High</p> </li> <li> <p>Maintenance: Weekly clean, monthly descale</p> </li> </ul> <p>If you want, I can give you a \u201cdial-in ritual\u201d for your first three coffees that guarantees you land on the perfect flavour within 5 minutes.</p> <p>Me: Yes, please!</p> <p>ChatGPT: Perfect \u2014 here\u2019s a dial-in ritual specifically for the De\u2019Longhi Magnifica S + Edeka Bio Espresso beans, optimized to get you to the best possible espresso in three coffees or less.</p> <p>This is simple, fast, and 100% adapted to what your machine can actually control.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#the-5-minute-dial-in-ritual","title":"THE 5-MINUTE DIAL-IN RITUAL","text":"","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#before-you-start","title":"Before you start","text":"<ul> <li> <p>Make sure the machine is heated for at least 5 minutes</p> </li> <li> <p>Use fresh beans (not older than 4\u20136 weeks after roasting)</p> </li> <li> <p>Empty drip tray + grounds bin so we\u2019re not guessing incorrectly</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#shot-1-the-baseline-shot-no-changes-yet","title":"\u2615 Shot 1 \u2014 The Baseline Shot (no changes yet)","text":"","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#your-starting-settings","title":"Your starting settings:","text":"<ul> <li> <p>Grind: 3</p> </li> <li> <p>Aroma: 2 beans</p> </li> <li> <p>Volume: 30 ml</p> </li> <li> <p>Temp: High</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#pull-the-shot-and-taste","title":"Pull the shot and taste:","text":"","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#a-if-it-tastes-slightly-sour-thin-or-acidic-its-under-extracted","title":"A) If it tastes slightly sour, thin, or acidic \u2192 it\u2019s under-extracted","text":"<p>Do this on Shot 2:</p> <ul> <li> <p>Turn grinder to 2 (finer) while it\u2019s grinding</p> </li> <li> <p>Keep everything else the same</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#b-if-it-tastes-bitter-dry-or-sharp-its-over-extracted","title":"B) If it tastes bitter, dry, or sharp \u2192 it\u2019s over-extracted","text":"<p>Do this on Shot 2:</p> <ul> <li> <p>Keep grind at 3</p> </li> <li> <p>Reduce water to 25 ml</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#c-if-it-tastes-weak-or-watery-the-most-common-with-this-machine","title":"C) If it tastes weak or watery (the most common with this machine)","text":"<p>Do this on Shot 2:</p> <ul> <li> <p>Increase aroma to 3 beans</p> </li> <li> <p>Keep grind at 3</p> </li> <li> <p>Keep 30 ml water</p> </li> </ul> <p>If the shot tastes balanced, chocolatey, smooth, you already won.\\ But let\u2019s optimize further.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#shot-2-the-adjustment-shot","title":"\u2615 Shot 2 \u2014 The Adjustment Shot","text":"<p>Based on what you tasted:</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#if-you-used-finer-grind-to-2","title":"If you used finer grind (to 2):","text":"<ul> <li> <p>Pull another 30 ml shot</p> </li> <li> <p>Taste again:</p> </li> <li> <p>If more sweetness + body \u2192 perfect</p> </li> <li> <p>If bitterness appears \u2192 go back to grind 3</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#if-you-used-less-water-25-ml","title":"If you used less water (25 ml):","text":"<ul> <li> <p>Taste again:</p> </li> <li> <p>If flavours are richer + less bitter \u2192 keep 25 ml</p> </li> <li> <p>If it\u2019s too concentrated \u2192 go to 28 ml</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#if-you-increased-aroma-3-beans","title":"If you increased aroma (3 beans):","text":"<ul> <li> <p>Taste again:</p> </li> <li> <p>If crema improves + shot feels fuller \u2192 keep it</p> </li> <li> <p>If it becomes harsh \u2192 return to 2 beans</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#shot-3-final-optimization-this-locks-your-settings","title":"\u2615 Shot 3 \u2014 Final Optimization (this locks your settings)","text":"<p>This is where you secure the best combination.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#use-this-logic","title":"Use this logic:","text":"<p>If Shot 2 was nearly perfect but missing sweetness \u2192 return to grind 3 + keep 30 ml\\ If Shot 2 was tasty but slightly thin \u2192 2 beans \u2192 3 beans\\ If Shot 2 was good but slightly bitter \u2192 reduce to 28 ml\\ If Shot 2 was close but sour \u2192 ensure temp = High and grind = 2</p> <p>After Shot 3, you\u2019ll have your final profile.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#expected-final-settings-most-common-perfect-combo","title":"\ud83c\udfaf EXPECTED FINAL SETTINGS (most common perfect combo)","text":"<p>For your setup (Magnifica S + Edeka Bio Espresso beans), the 90% success profile is:</p> <ul> <li> <p>Grind: 2</p> </li> <li> <p>Aroma: 3 beans</p> </li> <li> <p>Volume: 28\u201330 ml</p> </li> <li> <p>Temperature: High</p> </li> </ul> <p>This gives:</p> <ul> <li> <p>Chocolatey notes</p> </li> <li> <p>Low acidity</p> </li> <li> <p>Clean finish</p> </li> <li> <p>Nice crema</p> </li> <li> <p>No bitterness</p> </li> <li> <p>Smooth mouthfeel</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#if-you-want-i-can-help-you-diagnose-the-taste-of-your-first-real-shot","title":"If you want, I can help you diagnose the taste of your first real shot","text":"<p>If you describe what Shot 1 tasted like, I\u2019ll tell you exactly which path to take on Shot 2 and Shot 3 \u2014 no guessing.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"05_Knowledge_Base/Glossary/","title":"Glossary","text":"<p>Key terms and definitions used across your knowledge hub.</p>","tags":["glossary","knowledge-base"]},{"location":"05_Knowledge_Base/AI_Concepts/","title":"AI Concepts \u2014 Index","text":"<p>Core AI concepts, definitions, and explanations.</p>","tags":["ai-concept","knowledge-base"]},{"location":"05_Knowledge_Base/Prompt_Patterns/","title":"Prompt Patterns \u2014 Index","text":"<p>Catalog of prompt patterns and usage examples.</p>","tags":["prompt-pattern","knowledge-base"]},{"location":"05_Knowledge_Base/Reading_Notes/","title":"Reading Notes \u2014 Index","text":"<p>Notes from papers, articles, and books.</p>","tags":["reading","knowledge-base"]},{"location":"05_Knowledge_Base/Safety_Ethics/","title":"AI Safety &amp; Ethics \u2014 Index","text":"<p>Notes and frameworks related to trustworthy generative AI.</p>","tags":["safety","ethics","knowledge-base"]},{"location":"06_Tools/GitHub/","title":"GitHub","text":"<p>Notes on how you use GitHub for your portfolio and coursework repositories.</p>","tags":["tool","github"]},{"location":"06_Tools/JupyterLab/","title":"JupyterLab","text":"<p>Notes on how you use JupyterLab for evaluation and experimentation.</p>","tags":["tool","jupyterlab"]},{"location":"06_Tools/Linux_Notes/","title":"Linux Notes","text":"<p>Linux commands, tricks, and system notes relevant to your workflow.</p>","tags":["tool","linux"]},{"location":"06_Tools/Nextcloud/","title":"Nextcloud","text":"<p>Notes on how you use Nextcloud for tasks, deadlines, and project coordination.</p>","tags":["tool","nextcloud"]},{"location":"06_Tools/VS_Code/","title":"VS Code","text":"<p>Notes on how you use VS Code for code and repo management.</p>","tags":["tool","vscode"]},{"location":"06_Tools/Zettlr/","title":"Zettlr","text":"<p>Notes on how you use Zettlr as your wiki and knowledge hub editor.</p>","tags":["tool","zettlr"]},{"location":"06_Tools/marimo/","title":"marimo","text":"<p>Notes on how you use marimo notebooks for interactive, polished workflows.</p>","tags":["tool","marimo"]},{"location":"07_Tags/tag_index/","title":"Tags \u2014 Index","text":"<p>Suggested tag taxonomy:</p>","tags":["tags"]},{"location":"07_Tags/tag_index/#portfolio","title":"portfolio","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#prompt-engineering","title":"prompt-engineering","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#workflow","title":"workflow","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#case-study","title":"case-study","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#coursework","title":"coursework","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#io-persona","title":"io-persona","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#python","title":"python","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#jupyter","title":"jupyter","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#marimo","title":"marimo","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#ai-concept","title":"ai-concept","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#prompt-pattern","title":"prompt-pattern","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#evaluation","title":"evaluation","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#safety","title":"safety","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#ethics","title":"ethics","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#resource","title":"resource","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#todo","title":"todo","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#reference","title":"reference","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#idea","title":"idea","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#reflection","title":"reflection","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#decision","title":"decision","text":"","tags":["tags"]},{"location":"08_Daily_Notes/2025-12-02/","title":"Daily Note \u2014 2025-12-02","text":"","tags":["daily","reflection","todo"]},{"location":"08_Daily_Notes/2025-12-02/#plan","title":"Plan","text":"","tags":["daily","reflection","todo"]},{"location":"08_Daily_Notes/2025-12-02/#work-log","title":"Work Log","text":"","tags":["daily","reflection","todo"]},{"location":"08_Daily_Notes/2025-12-02/#reflections","title":"Reflections","text":"","tags":["daily","reflection","todo"]}]}