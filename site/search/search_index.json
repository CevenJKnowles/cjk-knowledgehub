{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"CJK KnowledgeHub","text":"<p>Welcome to the CJK KnowledgeHub \u2014 my unified space for AI engineering, prompt design, systems thinking, and portfolio building.</p> <p>This Hub acts as both:</p> <ul> <li>A personal research engine, where I document how I learn, experiment, and reason.</li> <li>A professional portfolio infrastructure, where I showcase real workflows, case studies, and long-term projects.</li> </ul>"},{"location":"#main-sections","title":"Main Sections","text":"<ul> <li>\ud83c\udfe0 Home   Landing pages, system instructions, and the structural overview of the Hub.   \u2192 Start here if you want context:  </li> <li>Welcome </li> <li>How this Hub works </li> <li> <p>Structure</p> </li> <li> <p>\u2b50 Featured Work (Portfolio)   Case studies and portfolio-oriented projects.  </p> </li> <li>Prompt Engineering Portfolio Hub </li> <li>Case Studies </li> <li>Conversational AI Hub </li> <li> <p>Portfolio Infrastructure Hub</p> </li> <li> <p>\ud83e\udd16 Io Persona (Flagship Project)   The evolving Io persona blueprints, protocols, and architecture.  </p> </li> <li>Io Overview </li> <li>IO-I, IO-II, IO-III blueprints (v1.0 \u2192 v1.4_dev and beyond)  </li> <li> <p>Experiments &amp; scratchpads</p> </li> <li> <p>\ud83e\uddea Workflows   Practical pipelines for creative work, coding, evaluation, prompting, and research.  </p> </li> <li>Code Notebooks </li> <li>Creative Workflows </li> <li>Evaluation </li> <li>Prompting </li> <li> <p>Research</p> </li> <li> <p>\ud83c\udf93 Coursework   Structured notes and artifacts from Coursera and other programs.  </p> </li> <li>Certificates </li> <li>Google IT Automation with Python </li> <li>IBM Generative AI Engineering </li> <li> <p>Vanderbilt Prompt Engineering Specialization</p> </li> <li> <p>\ud83d\udcda Knowledge Base   AI concepts, glossary, reading notes, and safety/ethics.  </p> </li> <li>AI Concepts </li> <li>Glossary </li> <li>Prompt Patterns </li> <li>Reading Notes </li> <li> <p>Safety &amp; Ethics</p> </li> <li> <p>\ud83d\udee0 Tools   Environment notes for GitHub, JupyterLab, Linux, VS Code, Zettlr, marimo, Nextcloud, and more.</p> </li> <li> <p>\ud83c\udff7 Tags &amp; \ud83e\uddfe Daily Notes </p> </li> <li>Tag Index for cross-referencing  </li> <li>Daily Notes for timestamped work logs</li> </ul>"},{"location":"#how-to-run-this-hub-locally","title":"How to Run This Hub Locally","text":"<p>```bash</p>"},{"location":"#from-the-project-root","title":"From the project root","text":"<p>mkdocs serve</p>"},{"location":"00_Home/","title":"\ud83e\udde0 CJK Knowledge Hub \u2014 Home","text":"<p>Welcome to your central wiki for:</p> <ul> <li>AI career development  </li> <li>prompt engineering  </li> <li>workflow design  </li> <li>IO Persona evolution  </li> <li>coursework integration  </li> <li>knowledge accumulation  </li> </ul> <p>Use this as your entry point into the rest of the system.</p>","tags":["home","overview"]},{"location":"00_Home/#main-areas","title":"Main Areas","text":"<ul> <li>[[../01_Projects/Prompt_Engineering_Portfolio/hub.md|Prompt Engineering Portfolio]]</li> <li>[[../02_IO_Persona/io_overview.md|IO Persona System]]</li> <li>[[../03_Workflows/Prompting/index.md|Workflows \u2014 Prompting]]</li> <li>[[../04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/index.md|Coursework \u2014 Vanderbilt Specialization]]</li> <li>[[../05_Knowledge_Base/Prompt_Patterns/index.md|Knowledge Base \u2014 Prompt Patterns]]</li> <li>[[../06_Tools/Zettlr.md|Tools]]</li> <li>[[../07_Tags/tag_index.md|Tags]]</li> <li>[[../08_Daily_Notes/2025-12-02.md|Daily Notes]]</li> </ul>","tags":["home","overview"]},{"location":"00_Home/instructions/","title":"How to Use This Knowledge Hub","text":"<ol> <li>Start each session at [[index.md]].</li> <li>Log work and reflections in the latest daily note in <code>08_Daily_Notes/</code>.</li> <li>For portfolio work, use:</li> <li>[[../01_Projects/Prompt_Engineering_Portfolio/hub.md|Prompt Engineering Portfolio Hub]]</li> <li>For IO persona evolution, use:</li> <li>[[../02_IO_Persona/io_overview.md|IO Persona Overview]]</li> <li>For coursework, use:</li> <li>[[../04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/index.md]]</li> </ol> <p>This hub is designed to evolve with your workflow and portfolio.</p>","tags":["instructions","meta"]},{"location":"00_Home/structure/","title":"Structure Overview","text":"","tags":["structure","meta"]},{"location":"00_Home/structure/#00_home","title":"00_Home","text":"<p>Entry point, structure documentation, usage instructions.</p>","tags":["structure","meta"]},{"location":"00_Home/structure/#01_projects","title":"01_Projects","text":"<p>Active projects (portfolio, case studies, conversational AI, infrastructure).</p>","tags":["structure","meta"]},{"location":"00_Home/structure/#02_io_persona","title":"02_IO_Persona","text":"<p>All IO persona generations (IO-I, IO-II, IO-III), blueprints and notes.</p>","tags":["structure","meta"]},{"location":"00_Home/structure/#03_workflows","title":"03_Workflows","text":"<p>Prompting, evaluation, research, code, and creative workflows.</p>","tags":["structure","meta"]},{"location":"00_Home/structure/#04_coursework","title":"04_Coursework","text":"<p>Vanderbilt Prompt Engineering Specialization, Google IT Automation with Python, IBM GenAI, certificates.</p>","tags":["structure","meta"]},{"location":"00_Home/structure/#05_knowledge_base","title":"05_Knowledge_Base","text":"<p>Prompt patterns, AI concepts, safety &amp; ethics, glossary, reading notes.</p>","tags":["structure","meta"]},{"location":"00_Home/structure/#06_tools","title":"06_Tools","text":"<p>Usage notes for Zettlr, GitHub, JupyterLab, marimo, VS Code, Nextcloud, Linux.</p>","tags":["structure","meta"]},{"location":"00_Home/structure/#07_tags","title":"07_Tags","text":"<p>Tag index and conventions.</p>","tags":["structure","meta"]},{"location":"00_Home/structure/#08_daily_notes","title":"08_Daily_Notes","text":"<p>Date-based notes for logging work, reflections, and tasks.</p>","tags":["structure","meta"]},{"location":"01_Projects/Case_Studies/","title":"Case Studies \u2014 Index","text":"<p>List and link your case studies here.</p>","tags":["case-study","portfolio"]},{"location":"01_Projects/Conversational_AI/hub/","title":"Conversational AI \u2014 Project Hub","text":"<p>Placeholder hub for future conversational and interaction design projects.</p>","tags":["conversational-ai","portfolio"]},{"location":"01_Projects/Portfolio_Infrastructure/hub/","title":"Portfolio Infrastructure \u2014 Project Hub","text":"<p>Notes and decisions about how your GitHub, wiki, and tools are organized.</p>","tags":["portfolio","infrastructure"]},{"location":"01_Projects/Prompt_Engineering_Portfolio/backlog/","title":"Backlog \u2014 Prompt Engineering Portfolio","text":"","tags":["portfolio","backlog"]},{"location":"01_Projects/Prompt_Engineering_Portfolio/backlog/#ready","title":"Ready","text":"<ul> <li>[ ] Create GitHub repo <code>prompt-engineering-portfolio</code></li> <li>[ ] Define repo README structure</li> <li>[ ] Draft 5\u201310 core prompt templates</li> <li>[ ] Sketch first workflow (content generation)</li> <li>[ ] Sketch first evaluation notebook</li> </ul>","tags":["portfolio","backlog"]},{"location":"01_Projects/Prompt_Engineering_Portfolio/backlog/#in-progress","title":"In Progress","text":"<ul> <li>[ ] </li> </ul>","tags":["portfolio","backlog"]},{"location":"01_Projects/Prompt_Engineering_Portfolio/backlog/#done","title":"Done","text":"<ul> <li>[x] Define project hub and backlog</li> </ul>","tags":["portfolio","backlog"]},{"location":"01_Projects/Prompt_Engineering_Portfolio/decisions/","title":"Decision Log \u2014 Prompt Engineering Portfolio","text":"<p>Record key decisions here.</p>","tags":["portfolio","decisions"]},{"location":"01_Projects/Prompt_Engineering_Portfolio/decisions/#decisions","title":"Decisions","text":"<ul> <li>2025-12-02 \u2014 Use <code>prompt-engineering-portfolio</code> as flagship GitHub repo name.</li> <li>2025-12-02 \u2014 Structure portfolio around prompt library, workflows, evaluation, and case studies.</li> </ul>","tags":["portfolio","decisions"]},{"location":"01_Projects/Prompt_Engineering_Portfolio/hub/","title":"Prompt Engineering Portfolio \u2014 Project Hub","text":"<p>This section of the CJK KnowledgeHub is dedicated to my work in prompt engineering. It serves as the project hub for case studies, experiments, coursework integrations, and long-term systems like the Io Persona.</p> <p>The goal of this hub is to show how I think, design, and iterate with large language models \u2013 not just final outputs.</p>"},{"location":"01_Projects/Prompt_Engineering_Portfolio/hub/#1-what-lives-in-this-portfolio","title":"1. What Lives in This Portfolio?","text":"<p>This portfolio gathers together:</p> <ul> <li>Case Studies   End-to-end explorations that highlight:</li> <li>problem framing  </li> <li>prompt design and iteration  </li> <li>reasoning and verification strategies  </li> <li> <p>outcomes and reflections  </p> </li> <li> <p>Patterns &amp; Techniques   Practical applications of prompt patterns such as:</p> </li> <li>Few-shot prompting  </li> <li>Game-play, Template, Recipe, and Meta-language patterns  </li> <li> <p>Reasoning and evaluation workflows  </p> </li> <li> <p>Systems &amp; Workflows   How I combine:</p> </li> <li>Io Persona  </li> <li>prompt patterns  </li> <li>external tools (JupyterLab, GitHub, etc.)   into repeatable workflows that can be used in real projects.</li> </ul> <p>Over time, this hub will become the main public-facing entry point to my prompt engineering work.</p>"},{"location":"01_Projects/Prompt_Engineering_Portfolio/hub/#2-structure-of-this-section","title":"2. Structure of This Section","text":"<p>The <code>Prompt_Engineering_Portfolio</code> folder is organised to support both storytelling and internal iteration:</p> <ul> <li> <p><code>hub.md</code>   \u2192 This page. High-level overview and navigation entry point.</p> </li> <li> <p><code>backlog.md</code> (internal working file)   \u2192 List of ideas, future case studies, and experiments I plan to develop.</p> </li> <li> <p><code>decisions.md</code> (internal working file)   \u2192 Design decisions, trade-offs, and rationale behind how I structure prompts, workflows, and this portfolio over time.</p> </li> <li> <p><code>workflow_notes.md</code> (internal working file)   \u2192 Notes on prompt workflows, iteration loops, evaluation setups, and experiment logs.</p> </li> </ul> <p>These internal pages are not meant as polished case studies; they show the thinking and planning that sits behind the public-facing work.</p>"},{"location":"01_Projects/Prompt_Engineering_Portfolio/hub/#3-relationship-to-vanderbilt-prompt-engineering-coursework","title":"3. Relationship to Vanderbilt Prompt Engineering Coursework","text":"<p>Many of the ideas and experiments here are grounded in the Vanderbilt Prompt Engineering Specialization (Coursera):</p> <ul> <li>Course 1 \u2014 Prompt Engineering for ChatGPT </li> <li>Course 2 \u2014 ChatGPT Advanced Data Analysis </li> <li>Course 3 \u2014 Trustworthy Generative AI</li> </ul> <p>I treat that coursework as:</p> <ul> <li>a knowledge base (patterns, frameworks, best practices), and  </li> <li>a launch pad for my own case studies, workflows, and Io Persona evolution.</li> </ul> <p>Concrete course notes, tests, and sandbox prompts live under:</p> <ul> <li><code>04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/...</code></li> </ul> <p>This hub will reference that material selectively, focusing on how I apply those concepts in real work.</p>"},{"location":"01_Projects/Prompt_Engineering_Portfolio/hub/#4-for-recruiters-collaborators-and-reviewers","title":"4. For Recruiters, Collaborators, and Reviewers","text":"<p>If you are evaluating my profile, this section is designed to demonstrate:</p> <ul> <li>Practical Prompt Engineering Skill</li> <li>clear problem decomposition  </li> <li>structured prompts and patterns  </li> <li> <p>iterative improvement instead of one-shot answers  </p> </li> <li> <p>Reasoning &amp; Verification Mindset</p> </li> <li>awareness of hallucinations and model limits  </li> <li>explicit verification steps and protocols  </li> <li> <p>use of tools (code, docs, tests) alongside language models  </p> </li> <li> <p>Systemic Thinking</p> </li> <li>connecting prompt design with Io Persona  </li> <li>designing processes, not just isolated prompts  </li> <li>building reusable workflows and documentation</li> </ul> <p>Future additions will include:</p> <ul> <li>Fully written case studies  </li> <li>Side-by-side \u201cprompt \u2192 iteration \u2192 outcome\u201d breakdowns  </li> <li>Links into Io Persona blueprints where relevant</li> </ul>"},{"location":"01_Projects/Prompt_Engineering_Portfolio/hub/#5-how-to-navigate-from-here","title":"5. How to Navigate from Here","text":"<p>Use this hub as your starting point:</p> <ul> <li>For polished narratives \u2192 go to the Case Studies section from the main navigation.  </li> <li>For a peek into the thinking behind the scenes:</li> <li><code>Backlog</code> </li> <li><code>Decisions</code> </li> <li><code>Workflow Notes</code> </li> </ul> <p>As the portfolio grows, this page will remain the anchor for everything related to Prompt Engineering in the CJK KnowledgeHub.</p>"},{"location":"01_Projects/Prompt_Engineering_Portfolio/workflow_notes/","title":"Workflow Notes \u2014 Prompt Engineering Portfolio","text":"<p>Use this file to sketch and refine workflows before turning them into formal documentation or notebooks.</p> <ul> <li>Link to final workflows in <code>03_Workflows/</code>.</li> </ul>","tags":["portfolio","workflow"]},{"location":"02_IO_Persona/io_overview/","title":"Io Persona \u2014 Flagship AI Collaboration Project","text":"<p>The Io Persona is my long-running, evolving collaboration with large language models. It started as a simple \u201cassistant persona\u201d and has grown into a multi-version system that explores prompt engineering, reasoning frameworks, alignment protocols, and long-term human\u2013AI partnership.</p> <p>This section of the KnowledgeHub documents the design, evolution, and practical use of Io as both: - a project (with versions, roadmaps, experiments), and - a tool I use daily for learning, workflows, and portfolio work.</p>"},{"location":"02_IO_Persona/io_overview/#1-what-is-io","title":"1. What is Io?","text":"<p>Io is a persona blueprint that defines how an AI system should think, respond, and collaborate with me.</p> <p>It includes, for example:</p> <ul> <li>Core traits (design thinking, directness, honesty, reasoning)</li> <li>Modes (Tutor, Collaborator, Challenger, Synthesizer, Visionary)</li> <li>Protocols for:</li> <li>accuracy &amp; verification  </li> <li>handling ambiguity and drift  </li> <li>reflective summaries and meta-cognition</li> </ul> <p>Over time, Io has become a living system design, not just a prompt. Each version builds on previous ones, tightening structure while preserving personality.</p>"},{"location":"02_IO_Persona/io_overview/#2-version-timeline-at-a-glance","title":"2. Version Timeline at a Glance","text":"<p>This hub summarises the major stages of the project. Detailed blueprints live in their own documents (linked where appropriate).</p>"},{"location":"02_IO_Persona/io_overview/#io-i-early-persona-blueprint","title":"Io-I \u2014 Early Persona Blueprint","text":"<p>Focus: first experiments with persona structure, tone, and collaboration.</p> <ul> <li>Defined initial traits and collaboration style  </li> <li>Learned what doesn\u2019t work: overspecification, vagueness, and drift  </li> <li>Captured as a set of evolving blueprints</li> </ul> <p>Key reference:</p> <ul> <li><code>IO-I v1.2 \u2014 Blueprint</code></li> </ul> <p>(Earlier versions <code>v1.0</code> and <code>v1.1</code> are kept as archival iterations and can be referenced internally when needed.)</p>"},{"location":"02_IO_Persona/io_overview/#io-ii-systematised-persona-protocols","title":"Io-II \u2014 Systematised Persona &amp; Protocols","text":"<p>Focus: turning Io into a system with clear protocols, modes, and alignment rules.</p> <p>Io-II introduces:</p> <ul> <li>Structured modes (Tutor, Collaborator, Challenger, etc.)</li> <li>Accuracy Alignment and verification habits  </li> <li>Ambiguity Protocols (how Io asks questions when something is unclear)  </li> <li>Clearer separation between:</li> <li>What Io is (persona blueprint)</li> <li>How Io behaves (protocols and workflows)</li> </ul> <p>Key reference:</p> <ul> <li><code>IO-II v1.3 \u2014 Blueprint</code></li> </ul> <p>There is also a development branch for the next iteration:</p> <ul> <li><code>IO-II v1.4_dev \u2014 Blueprint</code></li> </ul> <p>This dev version is where I experiment with a streamlined \u201ckernel\u201d that can later be ported across tools and local models.</p>"},{"location":"02_IO_Persona/io_overview/#io-iii-towards-a-local-multi-agent-system","title":"Io-III \u2014 Towards a Local, Multi-Agent System","text":"<p>Focus: shaping Io as a future local AI system with multiple agents and tools.</p> <p>Io-III is still in concept and planning, but the direction includes:</p> <ul> <li>Running Io-like personas on local models </li> <li>Designing multi-agent orchestration (e.g., specialist agents for reasoning, tooling, UX)  </li> <li>Exploring hardware and sensor integration in the long term</li> </ul> <p>Key references:</p> <ul> <li><code>Io-III Roadmap</code> </li> <li><code>Io-III v0.1 \u2014 Concepts &amp; Blueprint</code></li> </ul>"},{"location":"02_IO_Persona/io_overview/#3-what-this-project-demonstrates-for-reviewers","title":"3. What This Project Demonstrates (For Reviewers)","text":"<p>For hiring managers, recruiters, and peers, the Io Persona project demonstrates:</p> <ul> <li>Prompt Engineering Depth </li> <li>multi-layer persona design  </li> <li>protocol-driven prompting (accuracy, ambiguity, drift handling)  </li> <li> <p>experimentation across many versions</p> </li> <li> <p>Systems Thinking </p> </li> <li>treating \u201ca prompt\u201d as a designed system </li> <li>versioning, dev branches (<code>v1.4_dev</code>), and roadmaps  </li> <li> <p>preparation for local, multi-agent architectures</p> </li> <li> <p>Long-Term Human\u2013AI Collaboration </p> </li> <li>continuous refinement since early 2025  </li> <li>real use in learning (Python, AI engineering, workflows)  </li> <li>reflection on how to build trustworthy AI behaviour</li> </ul>"},{"location":"02_IO_Persona/io_overview/#4-how-to-navigate-this-section","title":"4. How to Navigate This Section","text":"<p>Use this page as the entry point into the Io project:</p> <ul> <li>Start here to understand the big picture </li> <li>Then follow links to specific blueprints and roadmaps when you want detail  </li> <li>Treat Io as both:</li> <li>a case study in prompt/system design, and  </li> <li>a companion system that supports the rest of this KnowledgeHub</li> </ul> <p>Future additions in this section will include:</p> <ul> <li>Visual diagrams of the Io-system architecture  </li> <li>Side-by-side comparisons of persona versions  </li> <li>Concrete examples of Io in real workflows (code, research, UX, evaluation)</li> </ul>"},{"location":"02_IO_Persona/IO-I/notes/","title":"IO-I \u2014 Notes","text":"<p>High-level notes about IO-I persona design and behavior.</p>","tags":["io-persona","io-i"]},{"location":"02_IO_Persona/IO-II/notes/","title":"IO-II \u2014 Notes","text":"<p>High-level notes about IO-II persona evolution and versions.</p>","tags":["io-persona","io-ii"]},{"location":"02_IO_Persona/IO-III/roadmap/","title":"IO-III \u2014 Roadmap","text":"<p>High-level ideas and milestones for IO-III as a multi-agent, sensor-integrated system.</p>","tags":["io-persona","io-iii"]},{"location":"02_IO_Persona/experiments/scratchpad/","title":"IO Persona \u2014 Experiments Scratchpad","text":"<p>Use this for quick persona-related experiments before formalizing changes.</p>","tags":["io-persona","experiments"]},{"location":"03_Workflows/Code_Notebooks/","title":"Workflows \u2014 Code &amp; Notebooks","text":"<p>Index of workflows involving JupyterLab, marimo, and Python for evaluation or automation.</p>","tags":["workflow","notebooks"]},{"location":"03_Workflows/Creative/","title":"Workflows \u2014 Creative","text":"<p>Index of creative workflows (e.g., narrative design, interactive experiences, scripts, content design).</p>","tags":["workflow","creative"]},{"location":"03_Workflows/Evaluation/","title":"Workflows \u2014 Evaluation","text":"<p>Index of workflows for testing prompts, measuring quality, and detecting hallucinations.</p>","tags":["workflow","evaluation"]},{"location":"03_Workflows/Prompting/","title":"Workflows \u2014 Prompting","text":"<p>Index of prompting workflows (e.g., content generation, research assistant, evaluation prompts).</p>","tags":["workflow","prompt-engineering"]},{"location":"03_Workflows/Research/","title":"Workflows \u2014 Research","text":"<p>Index of workflows for research, long-doc analysis, and structured reading.</p>","tags":["workflow","research"]},{"location":"04_Coursework/Certificates/","title":"Certificates \u2014 Index","text":"<p>List your earned certificates and relevant details here.</p>","tags":["certificates"]},{"location":"04_Coursework/Google_IT_Automation_with_Python/","title":"Google IT Automation with Python \u2014 Index","text":"<p>Use this folder for your notes and module summaries.</p>","tags":["coursework","google","python"]},{"location":"04_Coursework/IBM_Generative_AI_Engineering_Professional_Certificate/","title":"IBM Generative AI Engineering Professional Certificate \u2014 Index","text":"<p>Use this folder for IBM course notes and integration with your portfolio.</p>","tags":["coursework","ibm","generative-ai"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/","title":"Prompt Engineering Specialization \u2014 Notes Portal","text":"<p>This site is a lightweight view of my structured notes.</p> <p>Full repository: https://github.com/CevenJKnowles/prompt-engineering-specialization</p>","tags":["PromptEngineering","AIEngineering","course_unknown","module_0","index","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/","title":"Graded Assignment 1","text":"","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#creating-your-first-prompts","title":"Creating Your First Prompts","text":"","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#1-create-a-prompt-for-a-large-language-model-such-as-chatgpt-to-describe-how-large-language-models-work-ask-at-least-three-follow-up-questions-based-on-the-output-provide-the-prompts-and-outputs-from-the-conversation-as-the-answer","title":"1. Create a prompt for a large language model, such as ChatGPT, to describe how large language models work. Ask at least three follow-up questions based on the output. Provide the prompts and outputs from the conversation as the answer.","text":"","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#answer","title":"Answer","text":"<p>Me: Can you summarise in one paragraph how large language models work?</p> <p>ChatGPT: Large language models learn statistical patterns in text by training on enormous datasets, adjusting billions of internal parameters to predict the next token in a sequence. Through this repeated prediction process, they build a layered internal representation of grammar, semantics, reasoning patterns, factual associations, and even task structures. At runtime, the model takes an input prompt, encodes it into vectors, and then generates tokens one by one\u2014each step influenced by both the prompt and its learned internal patterns\u2014allowing it to produce coherent responses, follow instructions, or solve problems without explicit programming.</p> <p>Me: Is this the same across all LLMs?</p> <p>ChatGPT: Broadly yes\u2014but with meaningful variations.</p> <p>Almost all LLMs share the same core principle: they learn by predicting the next token and adjusting internal parameters to capture patterns in language. This predictive-learning architecture (the Transformer) is the common foundation behind GPT, Claude, Gemini, LLaMA, Mistral, and most modern open-source models.</p> <p>However, they differ in important ways:</p> <ul> <li>Training data: size, diversity, quality, and recency vary widely.</li> <li>Model size and architecture tweaks: some use standard Transformers, others use mixtures-of-experts (MoE), rotary positional embeddings, or optimized attention mechanisms.</li> <li>Fine-tuning strategy: instruction tuning, reinforcement learning from human feedback (RLHF), preference optimization (DPO), or domain-specialized training can change the model\u2019s style and capabilities.</li> <li>Inference techniques: sampling strategies, caching, parallelism, and quantization differ across model families.</li> </ul> <p>So the fundamental mechanism is shared, but the capabilities, behavior, and efficiency can differ substantially depending on these design choices.</p> <p>Me: What are the differences between Transformers, MoE, rotary positional embeddings, and optimized attention mechanisms?</p> <p>ChatGPT: Here\u2019s a clean, high-resolution breakdown of the four concepts and how they differ:</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#1-transformers-the-overall-architecture","title":"1. Transformers (the overall architecture)","text":"<p>What they are:\\ The core neural architecture behind almost all modern LLMs.</p> <p>Key idea:\\ Transformers use self-attention to let every token look at every other token in the input, learning relationships across a sequence without relying on recurrence (RNNs) or convolution (CNNs).</p> <p>Why it matters:\\ This architecture scales extremely well and captures long-range dependencies in language.</p> <p>Think of it as:\\ The entire building\u2014all other items below are components or upgrades inside that building.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#2-mixture-of-experts-moe","title":"2. Mixture-of-Experts (MoE)","text":"<p>What it is:\\ A scaling technique where the model contains multiple \u201cexpert\u201d subnetworks, but only a small subset is activated per token using a gating network.</p> <p>Key idea:\\ Instead of making one huge dense model, MoE spreads capacity across many experts while keeping compute low at inference.</p> <p>Why it matters:</p> <ul> <li> <p>Higher capacity without proportional compute cost</p> </li> <li> <p>More specialization: different experts may handle different linguistic or reasoning patterns</p> </li> </ul> <p>Think of it as:\\ A neighborhood of specialists where only the right experts wake up depending on the token.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#3-rotary-positional-embeddings-rope","title":"3. Rotary Positional Embeddings (RoPE)","text":"<p>What they are:\\ A method for encoding token order into the model using rotations in a continuous vector space.</p> <p>Key idea:\\ Transformers need position info. RoPE does this efficiently and allows extrapolation to longer contexts better than older positional systems.</p> <p>Why it matters:</p> <ul> <li> <p>Enables long context windows (many current LLMs use RoPE extensions)</p> </li> <li> <p>More stable and smoother positional encoding than sinusoidal alternatives</p> </li> </ul> <p>Think of it as:\\ A mathematical compass that helps the model understand sequence order and distance.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#4-optimized-attention-mechanisms","title":"4. Optimized Attention Mechanisms","text":"<p>What they are:\\ A general category describing any improvement that makes attention faster, cheaper, or more memory-efficient.</p> <p>Examples:</p> <ul> <li> <p>FlashAttention (faster, memory-efficient exact attention)</p> </li> <li> <p>Multi-Query Attention (Mistral, GPT-4)\u2014reduces memory by sharing key/value projections</p> </li> <li> <p>Linear attention variants (for extreme long contexts)</p> </li> <li> <p>Sliding-window or blockwise attention (Gemini, Claude optimizations)</p> </li> </ul> <p>Key idea:\\ Standard attention scales with O(n\u00b2) memory/time. Optimizations reduce that cost so models can handle longer inputs or run faster.</p> <p>Why it matters:</p> <ul> <li> <p>Enables 100k\u20131M token contexts</p> </li> <li> <p>Reduces GPU requirements</p> </li> <li> <p>Improves latency</p> </li> </ul> <p>Think of it as:\\ Upgrading the engine of the Transformer so it can handle more data with less fuel.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#how-they-relate","title":"How they relate","text":"<ul> <li> <p>Transformer = the base architecture.</p> </li> <li> <p>Rotary positional embeddings = how positions are encoded inside the Transformer.</p> </li> <li> <p>Optimized attention = ways to compute attention more efficiently within the Transformer.</p> </li> <li> <p>MoE = a way to scale the Transformer by adding many specialized expert modules.</p> </li> </ul> <p>They are not competing concepts\u2014they are layers of evolution that can coexist in a single model.</p> <p>If you'd like, I can also map each method to real models (GPT-4/5, Claude, Gemini, LLaMA, Mistral), or build you a visual diagram summarizing how these components interact.</p> <p>Me: Could you give me a list of the top 5 major LLMs and which types of architecture they use?</p> <p>ChatGPT: Here\u2019s a breakdown of five major large-language-models (LLMs) and the architectures they use:</p> <p>Model   Developer   Architecture type GPT\u20114   OpenAI  Dense decoder-only Transformer (standard Transformer architecture)  newsletter.semianalysis.com +2 kafkai.com +2</p> <p>PaLM (~540B)    Google AI   Dense decoder-only Transformer (no public large-scale MoE disclosed for that version)  Wikipedia +1</p> <p>Gemini 1.5  DeepMind / Google   Transformer + Mixture-of-Experts (MoE) architecture (\u201cexpert\u201d subnetworks selectively activated)  blog.google +1</p> <p>LLaMA 4 (the latest by Meta AI) Meta AI Mixture-of-Experts (MoE) variant of the Transformer architecture (sparse routing)  AI Meta +2 Wikipedia +2</p> <p>Mixtral 8\u00d77B (open-source)  Mistral AI  Sparse mixture-of-experts Transformer: at each layer a router picks a subset of expert feed-forward networks.  arxiv.org +1</p> <p>If you like, I can extend this list to the top 10 models and include architecture details (dense vs sparse, long-context window, expert count, etc.).</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#2-create-a-prompt-for-a-large-language-model-such-as-chatgpt-that-asks-it-to-perform-an-instruction-other-than-answering-a-question-for-example-ask-chatgpt-to-create-a-meal-plan-plan-a-trip-create-a-recipe-or-help-you-diagnose-a-problem-provide-the-prompts-and-outputs-from-the-conversation-as-the-answer","title":"2. Create a prompt for a large language model, such as ChatGPT, that asks it to perform an instruction other than answering a question. For example, ask ChatGPT to create a meal plan, plan a trip, create a recipe, or help you diagnose a problem. Provide the prompts and outputs from the conversation as the answer.","text":"","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#answer_1","title":"Answer","text":"<p>Me: Can you tell me how to make the perfect espresso?</p> <p>ChatGPT: Absolutely \u2014 here\u2019s the distilled, no-nonsense version of how to pull a perfect espresso, based on what top baristas agree on. This is practical, reproducible, and tuned for taste clarity and consistency.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#the-perfect-espresso-the-core-formula","title":"The Perfect Espresso: The Core Formula","text":"","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#1-dose-the-coffee-amount","title":"1. Dose (the coffee amount)","text":"<ul> <li> <p>18\u201320 g of high-quality, freshly roasted beans</p> </li> <li> <p>Grind fresh and fine (about table-salt fine)</p> </li> <li> <p>Espresso is extremely sensitive to grind size \u2014 this is your main control dial.</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#2-distribution-tamping","title":"2. Distribution &amp; Tamping","text":"<ul> <li> <p>Shake or tap the portafilter to level the grounds</p> </li> <li> <p>Tamp with:</p> </li> <li> <p>~15\u201320 kg of pressure</p> </li> <li> <p>Perfectly even (the levelness matters more than the strength)</p> </li> </ul> <p>Goal: a uniform coffee bed that water passes through evenly.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#3-brew-ratio","title":"3. Brew Ratio","text":"<p>The gold standard:</p> <p>1:2 ratio\\ (For 18 g in \u2192 36 g out)</p> <p>This defines the balance between sweetness, acidity, and bitterness.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#4-brew-time","title":"4. Brew Time","text":"<ul> <li> <p>25\u201330 seconds, starting the moment you hit the button</p> </li> <li> <p>If it runs too fast \u2192 grind finer</p> </li> <li> <p>Too slow \u2192 grind coarser</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#5-water","title":"5. Water","text":"<ul> <li> <p>Temperature: 92\u201396\u00b0C</p> </li> <li> <p>Clean, filtered water with balanced minerals (not distilled)</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#6-shot-appearance","title":"6. Shot Appearance","text":"<p>Look for:</p> <ul> <li> <p>Steady, thick \u201cmouse tail\u201d stream</p> </li> <li> <p>Rich, even crema</p> </li> <li> <p>No blonding until the very end (pale yellow = extraction is done)</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#taste-calibration-the-secret","title":"Taste Calibration (the secret)","text":"<p>If the shot tastes sour \u2192 under-extracted \u2192 grind finer\\ If the shot tastes bitter \u2192 over-extracted \u2192 grind coarser\\ If the shot tastes hollow/thin \u2192 increase dose or reduce output\\ If the shot tastes muddy/overwhelming \u2192 decrease dose or increase output</p> <p>This is the real artistry.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#what-perfect-tastes-like","title":"What Perfect Tastes Like","text":"<p>A great espresso should be:</p> <ul> <li> <p>Sweet first</p> </li> <li> <p>Structured acidity</p> </li> <li> <p>Balanced bitterness</p> </li> <li> <p>Thick, syrupy mouthfeel</p> </li> <li> <p>Long, pleasant finish</p> </li> </ul> <p>Even a dark roast should still have clarity, not harshness.</p> <p>If you want, I can:</p> <ul> <li> <p>Give you a step-by-step ritual customized for your machine (manual, semi-auto, or fully automatic)</p> </li> <li> <p>Optimize for specific beans (light vs. dark roast)</p> </li> <li> <p>Help you troubleshoot crema, channeling, watery shots, bitter shots\u2014anything</p> </li> </ul> <p>Just tell me your setup and what beans you use.</p> <p>Me: Can you tell me the right way if I am using a Delonghi Magnifica S full automat machine with Edeka Bio Esspresso beans?</p> <p>ChatGPT: Absolutely \u2014 with a De\u2019Longhi Magnifica S and Edeka Bio Espresso beans, \u201cperfect espresso\u201d means optimising the machine\u2019s limited controls rather than chasing caf\u00e9-grade precision. Here\u2019s the right way to get the absolute best out of this specific setup.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#1-set-your-grinder-correctly-the-most-important-step","title":"1. Set Your Grinder Correctly (the most important step)","text":"<p>The Magnifica S has a built-in burr grinder with fixed steps.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#optimal-range-for-espresso","title":"Optimal range for espresso:","text":"<p>Setting 2\u20133 (counting from the finest side)</p> <p>How to adjust correctly:</p> <ul> <li> <p>Only change the grinder while the machine is grinding (to avoid damage).</p> </li> <li> <p>Reduce one step at a time \u2192 run 2\u20133 shots \u2192 taste \u2192 adjust again.</p> </li> </ul> <p>Why:\\ These machines grind a bit coarser than caf\u00e9 grinders, so you compensate by using the machine\u2019s lowest feasible grind setting.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#2-aroma-strength-setting","title":"2. Aroma (Strength) Setting","text":"<p>Use 2 or 3 beans (medium-high strength).</p> <p>This tells the machine to dose more coffee, which is crucial because automatic machines underdose by default.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#3-amount-of-water-the-espresso-volume","title":"3. Amount of Water (the espresso volume)","text":"<p>Set the espresso button to 30\u201335 ml.</p> <p>On a super-automatic machine, controlling volume is how you approximate the correct 1:2 ratio.</p> <ul> <li> <p>Less water = richer, sweeter, more syrupy</p> </li> <li> <p>More water = thinner, bitter</p> </li> </ul> <p>30\u201335 ml is the sweet spot.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#4-temperature-setting","title":"4. Temperature Setting","text":"<p>Set to HIGH.</p> <p>Why:\\ Automatic machines lose heat faster than commercial machines. High temp brings out sweetness and reduces sourness, especially with organic beans.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#5-beans-edeka-bio-espresso","title":"5. Beans: Edeka Bio Espresso","text":"<p>These beans are:</p> <ul> <li> <p>Medium-dark, a bit oily</p> </li> <li> <p>Designed for fully automatics</p> </li> <li> <p>Naturally chocolatey, mild, low acidity</p> </li> </ul> <p>What this means for tuning:</p> <ul> <li> <p>Finer grind works well</p> </li> <li> <p>Higher temperature is ideal</p> </li> <li> <p>Keep the espresso short (don\u2019t pull 60 ml singles \u2014 they go bitter fast)</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#6-maintenance-that-affects-taste","title":"6. Maintenance That Affects Taste","text":"<p>This is not optional \u2014 these machines are extremely sensitive:</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#weekly","title":"Weekly:","text":"<ul> <li> <p>Rinse brew group</p> </li> <li> <p>Clean coffee oil buildup from the chute</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#monthly","title":"Monthly:","text":"<ul> <li> <p>Use descaler</p> </li> <li> <p>Clean the grinder hopper</p> </li> <li> <p>Empty dredge + drip tray</p> </li> </ul> <p>Dirty machines = bitter, hollow, and inconsistent espresso.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#7-the-flavour-targets-for-this-setup","title":"7. The Flavour Targets for This Setup","text":"<p>With this machine + these beans, the \u201cperfect\u201d shot should taste:</p> <ul> <li> <p>Smooth</p> </li> <li> <p>Low acidity</p> </li> <li> <p>Mild bitterness, but not burnt</p> </li> <li> <p>Chocolatey with a slight nutty finish</p> </li> <li> <p>Medium body (Magnifica S can\u2019t produce caf\u00e9-level thickness)</p> </li> </ul> <p>If it tastes sour \u2192 grind finer or raise water temp\\ If it tastes bitter \u2192 grind coarser or reduce volume to 25\u201330 ml\\ If it tastes weak \u2192 increase aroma strength and reduce water volume\\ If it tastes burnt \u2192 reduce temperature to medium (rarely needed for this bean)</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#your-ideal-settings-summary","title":"Your Ideal Settings Summary","text":"<p>For De\u2019Longhi Magnifica S + Edeka Bio Espresso beans:</p> <ul> <li> <p>Grind: 2\u20133 (fine)</p> </li> <li> <p>Aroma strength: 2\u20133 beans</p> </li> <li> <p>Water volume: 30\u201335 ml</p> </li> <li> <p>Temperature: High</p> </li> <li> <p>Maintenance: Weekly clean, monthly descale</p> </li> </ul> <p>If you want, I can give you a \u201cdial-in ritual\u201d for your first three coffees that guarantees you land on the perfect flavour within 5 minutes.</p> <p>Me: Yes, please!</p> <p>ChatGPT: Perfect \u2014 here\u2019s a dial-in ritual specifically for the De\u2019Longhi Magnifica S + Edeka Bio Espresso beans, optimized to get you to the best possible espresso in three coffees or less.</p> <p>This is simple, fast, and 100% adapted to what your machine can actually control.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#the-5-minute-dial-in-ritual","title":"THE 5-MINUTE DIAL-IN RITUAL","text":"","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#before-you-start","title":"Before you start","text":"<ul> <li> <p>Make sure the machine is heated for at least 5 minutes</p> </li> <li> <p>Use fresh beans (not older than 4\u20136 weeks after roasting)</p> </li> <li> <p>Empty drip tray + grounds bin so we\u2019re not guessing incorrectly</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#shot-1-the-baseline-shot-no-changes-yet","title":"\u2615 Shot 1 \u2014 The Baseline Shot (no changes yet)","text":"","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#your-starting-settings","title":"Your starting settings:","text":"<ul> <li> <p>Grind: 3</p> </li> <li> <p>Aroma: 2 beans</p> </li> <li> <p>Volume: 30 ml</p> </li> <li> <p>Temp: High</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#pull-the-shot-and-taste","title":"Pull the shot and taste:","text":"","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#a-if-it-tastes-slightly-sour-thin-or-acidic-its-under-extracted","title":"A) If it tastes slightly sour, thin, or acidic \u2192 it\u2019s under-extracted","text":"<p>Do this on Shot 2:</p> <ul> <li> <p>Turn grinder to 2 (finer) while it\u2019s grinding</p> </li> <li> <p>Keep everything else the same</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#b-if-it-tastes-bitter-dry-or-sharp-its-over-extracted","title":"B) If it tastes bitter, dry, or sharp \u2192 it\u2019s over-extracted","text":"<p>Do this on Shot 2:</p> <ul> <li> <p>Keep grind at 3</p> </li> <li> <p>Reduce water to 25 ml</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#c-if-it-tastes-weak-or-watery-the-most-common-with-this-machine","title":"C) If it tastes weak or watery (the most common with this machine)","text":"<p>Do this on Shot 2:</p> <ul> <li> <p>Increase aroma to 3 beans</p> </li> <li> <p>Keep grind at 3</p> </li> <li> <p>Keep 30 ml water</p> </li> </ul> <p>If the shot tastes balanced, chocolatey, smooth, you already won.\\ But let\u2019s optimize further.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#shot-2-the-adjustment-shot","title":"\u2615 Shot 2 \u2014 The Adjustment Shot","text":"<p>Based on what you tasted:</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#if-you-used-finer-grind-to-2","title":"If you used finer grind (to 2):","text":"<ul> <li> <p>Pull another 30 ml shot</p> </li> <li> <p>Taste again:</p> </li> <li> <p>If more sweetness + body \u2192 perfect</p> </li> <li> <p>If bitterness appears \u2192 go back to grind 3</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#if-you-used-less-water-25-ml","title":"If you used less water (25 ml):","text":"<ul> <li> <p>Taste again:</p> </li> <li> <p>If flavours are richer + less bitter \u2192 keep 25 ml</p> </li> <li> <p>If it\u2019s too concentrated \u2192 go to 28 ml</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#if-you-increased-aroma-3-beans","title":"If you increased aroma (3 beans):","text":"<ul> <li> <p>Taste again:</p> </li> <li> <p>If crema improves + shot feels fuller \u2192 keep it</p> </li> <li> <p>If it becomes harsh \u2192 return to 2 beans</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#shot-3-final-optimization-this-locks-your-settings","title":"\u2615 Shot 3 \u2014 Final Optimization (this locks your settings)","text":"<p>This is where you secure the best combination.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#use-this-logic","title":"Use this logic:","text":"<p>If Shot 2 was nearly perfect but missing sweetness \u2192 return to grind 3 + keep 30 ml\\ If Shot 2 was tasty but slightly thin \u2192 2 beans \u2192 3 beans\\ If Shot 2 was good but slightly bitter \u2192 reduce to 28 ml\\ If Shot 2 was close but sour \u2192 ensure temp = High and grind = 2</p> <p>After Shot 3, you\u2019ll have your final profile.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#expected-final-settings-most-common-perfect-combo","title":"\ud83c\udfaf EXPECTED FINAL SETTINGS (most common perfect combo)","text":"<p>For your setup (Magnifica S + Edeka Bio Espresso beans), the 90% success profile is:</p> <ul> <li> <p>Grind: 2</p> </li> <li> <p>Aroma: 3 beans</p> </li> <li> <p>Volume: 28\u201330 ml</p> </li> <li> <p>Temperature: High</p> </li> </ul> <p>This gives:</p> <ul> <li> <p>Chocolatey notes</p> </li> <li> <p>Low acidity</p> </li> <li> <p>Clean finish</p> </li> <li> <p>Nice crema</p> </li> <li> <p>No bitterness</p> </li> <li> <p>Smooth mouthfeel</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#if-you-want-i-can-help-you-diagnose-the-taste-of-your-first-real-shot","title":"If you want, I can help you diagnose the taste of your first real shot","text":"<p>If you describe what Shot 1 tasted like, I\u2019ll tell you exactly which path to take on Shot 2 and Shot 3 \u2014 no guessing.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"05_Knowledge_Base/Glossary/","title":"Glossary","text":"<p>Key terms and definitions used across your knowledge hub.</p>","tags":["glossary","knowledge-base"]},{"location":"05_Knowledge_Base/AI_Concepts/","title":"AI Concepts \u2014 Index","text":"<p>Core AI concepts, definitions, and explanations.</p>","tags":["ai-concept","knowledge-base"]},{"location":"05_Knowledge_Base/Prompt_Patterns/","title":"Prompt Patterns \u2014 Index","text":"<p>Catalog of prompt patterns and usage examples.</p>","tags":["prompt-pattern","knowledge-base"]},{"location":"05_Knowledge_Base/Reading_Notes/","title":"Reading Notes \u2014 Index","text":"<p>Notes from papers, articles, and books.</p>","tags":["reading","knowledge-base"]},{"location":"05_Knowledge_Base/Safety_Ethics/","title":"AI Safety &amp; Ethics \u2014 Index","text":"<p>Notes and frameworks related to trustworthy generative AI.</p>","tags":["safety","ethics","knowledge-base"]},{"location":"06_Tools/GitHub/","title":"GitHub","text":"<p>Notes on how you use GitHub for your portfolio and coursework repositories.</p>","tags":["tool","github"]},{"location":"06_Tools/JupyterLab/","title":"JupyterLab","text":"<p>Notes on how you use JupyterLab for evaluation and experimentation.</p>","tags":["tool","jupyterlab"]},{"location":"06_Tools/Linux_Notes/","title":"Linux Notes","text":"<p>Linux commands, tricks, and system notes relevant to your workflow.</p>","tags":["tool","linux"]},{"location":"06_Tools/Nextcloud/","title":"Nextcloud","text":"<p>Notes on how you use Nextcloud for tasks, deadlines, and project coordination.</p>","tags":["tool","nextcloud"]},{"location":"06_Tools/VS_Code/","title":"VS Code","text":"<p>Notes on how you use VS Code for code and repo management.</p>","tags":["tool","vscode"]},{"location":"06_Tools/Zettlr/","title":"Zettlr","text":"<p>Notes on how you use Zettlr as your wiki and knowledge hub editor.</p>","tags":["tool","zettlr"]},{"location":"06_Tools/marimo/","title":"marimo","text":"<p>Notes on how you use marimo notebooks for interactive, polished workflows.</p>","tags":["tool","marimo"]},{"location":"07_Tags/tag_index/","title":"Tags \u2014 Index","text":"<p>Suggested tag taxonomy:</p>","tags":["tags"]},{"location":"07_Tags/tag_index/#portfolio","title":"portfolio","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#prompt-engineering","title":"prompt-engineering","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#workflow","title":"workflow","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#case-study","title":"case-study","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#coursework","title":"coursework","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#io-persona","title":"io-persona","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#python","title":"python","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#jupyter","title":"jupyter","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#marimo","title":"marimo","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#ai-concept","title":"ai-concept","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#prompt-pattern","title":"prompt-pattern","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#evaluation","title":"evaluation","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#safety","title":"safety","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#ethics","title":"ethics","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#resource","title":"resource","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#todo","title":"todo","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#reference","title":"reference","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#idea","title":"idea","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#reflection","title":"reflection","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#decision","title":"decision","text":"","tags":["tags"]},{"location":"08_Daily_Notes/2025-12-02/","title":"Daily Note \u2014 2025-12-02","text":"","tags":["daily","reflection","todo"]},{"location":"08_Daily_Notes/2025-12-02/#plan","title":"Plan","text":"","tags":["daily","reflection","todo"]},{"location":"08_Daily_Notes/2025-12-02/#work-log","title":"Work Log","text":"","tags":["daily","reflection","todo"]},{"location":"08_Daily_Notes/2025-12-02/#reflections","title":"Reflections","text":"","tags":["daily","reflection","todo"]}]}