{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"CJK KnowledgeHub","text":"<p>Welcome to the CJK KnowledgeHub \u2014 my unified space for AI engineering, prompt design, systems thinking, and portfolio building.</p> <p>This Hub acts as both:</p> <ul> <li>A personal research engine, where I document how I learn, experiment, and reason.</li> <li>A professional portfolio infrastructure, where I showcase real workflows, case studies, and long-term projects.</li> </ul>"},{"location":"#main-sections","title":"Main Sections","text":"<ul> <li>\ud83c\udfe0 Home   Landing pages, system instructions, and the structural overview of the Hub.   \u2192 Start here if you want context:  </li> <li>Welcome </li> <li>How this Hub works </li> <li> <p>Structure</p> </li> <li> <p>\u2b50 Featured Work (Portfolio)   Case studies and portfolio-oriented projects.  </p> </li> <li>Prompt Engineering Portfolio Hub </li> <li>Case Studies </li> <li>Conversational AI Hub </li> <li> <p>Portfolio Infrastructure Hub</p> </li> <li> <p>\ud83e\udd16 Io Persona (Flagship Project)   The evolving Io persona blueprints, protocols, and architecture.  </p> </li> <li>Io Overview </li> <li>IO-I, IO-II, IO-III blueprints (v1.0 \u2192 v1.4_dev and beyond)  </li> <li> <p>Experiments &amp; scratchpads</p> </li> <li> <p>\ud83e\uddea Workflows   Practical pipelines for creative work, coding, evaluation, prompting, and research.  </p> </li> <li>Code Notebooks </li> <li>Creative Workflows </li> <li>Evaluation </li> <li>Prompting </li> <li> <p>Research</p> </li> <li> <p>\ud83c\udf93 Coursework   Structured notes and artifacts from Coursera and other programs.  </p> </li> <li>Certificates </li> <li>Google IT Automation with Python </li> <li>IBM Generative AI Engineering </li> <li> <p>Vanderbilt Prompt Engineering Specialization</p> </li> <li> <p>\ud83d\udcda Knowledge Base   AI concepts, glossary, reading notes, and safety/ethics.  </p> </li> <li>AI Concepts </li> <li>Glossary </li> <li>Prompt Patterns </li> <li>Reading Notes </li> <li> <p>Safety &amp; Ethics</p> </li> <li> <p>\ud83d\udee0 Tools   Environment notes for GitHub, JupyterLab, Linux, VS Code, Zettlr, marimo, Nextcloud, and more.</p> </li> <li> <p>\ud83c\udff7 Tags &amp; \ud83e\uddfe Daily Notes </p> </li> <li>Tag Index for cross-referencing  </li> <li>Daily Notes for timestamped work logs</li> </ul>"},{"location":"#how-to-run-this-hub-locally","title":"How to Run This Hub Locally","text":"<p>```bash</p>"},{"location":"#from-the-project-root","title":"From the project root","text":"<p>mkdocs serve</p>"},{"location":"00_Home/","title":"CJK KnowledgeHub","text":"<p>Welcome to the CJK KnowledgeHub \u2014 my living workspace for learning, experimentation, and portfolio building in AI, prompt engineering, and digital systems design.</p> <p>This site hosts my projects, personas, workflows, coursework, and reference knowledge. It\u2019s both my personal lab notebook and the backbone of my future professional portfolio.</p>"},{"location":"00_Home/#what-this-hub-is-for","title":"What this hub is for","text":"<ul> <li>Documenting my journey from beginner to working AI professional  </li> <li>Building reusable workflows for prompting, evaluation, and reasoning  </li> <li>Capturing course notes and exercises from my ongoing learning paths  </li> <li>Designing and stress-testing the Io Persona, my long-term AI collaborator concept  </li> <li>Maintaining a structured knowledge base I can grow and refine over time  </li> </ul> <p>If you\u2019re a reviewer, recruiter, or collaborator, this hub shows how I think, how I organize complexity, and how I learn in public.</p>"},{"location":"00_Home/#featured-work","title":"Featured Work","text":""},{"location":"00_Home/#prompt-engineering-portfolio","title":"Prompt Engineering Portfolio","text":"<p>This is the practical heart of the hub.</p> <ul> <li>Hub: high-level overview of current and planned portfolio work  </li> <li>Backlog, decisions, and workflow notes: how I choose, refine, and execute projects  </li> <li>Focus on:</li> <li>Prompt pattern application in real tasks  </li> <li>Evaluation and error-analysis workflows  </li> <li>End-to-end prompting systems and documentation  </li> </ul> <p>\u2192 Navigate via: <code>Featured Work (Portfolio) \u2192 Prompt Engineering Portfolio Hub</code></p>"},{"location":"00_Home/#io-persona-flagship-project","title":"Io Persona \u2014 Flagship Project","text":"<p>The Io Persona is my long-term flagship: a designed AI \u201ccollaborator\u201d with explicit protocols, modes, and evolution across versions (IO-I \u2192 IO-II \u2192 IO-III).</p> <p>Inside this section you\u2019ll find:</p> <ul> <li>Overview: the concept, purpose, and evolution timeline  </li> <li>IO-I (v1.0\u2013v1.2): early experiments and blueprint drafts  </li> <li>IO-II (v1.2\u2013v1.4 dev): current active persona with richer protocols and alignment rules  </li> <li>IO-III (v0.1 concepts): early thinking about future, multi-agent, local, and embodied directions  </li> <li>Experiments: scratchpads and test ideas that don\u2019t yet belong in a formal blueprint  </li> </ul> <p>This project connects prompt engineering, AI safety/ethics, UX, and systems design into one evolving artefact.</p> <p>\u2192 Navigate via: <code>Io Persona (Flagship Project)</code></p>"},{"location":"00_Home/#workflows-systems","title":"Workflows &amp; Systems","text":"<p>The Workflows section contains the practical \u201chow I work\u201d layer:</p> <ul> <li>Code Notebooks: notes on using notebooks and coding workflows  </li> <li>Creative Workflows: ideation, storytelling, and design flows  </li> <li>Evaluation Workflows: how I check quality, reason about errors, and iterate  </li> <li>Prompting: specific prompting flows and interaction patterns  </li> <li>Research: how I structure reading, note-taking, and synthesis  </li> </ul> <p>These pages are about repeatable processes, not just final outputs.</p> <p>\u2192 Navigate via: <code>Workflows</code></p>"},{"location":"00_Home/#coursework-learning-paths","title":"Coursework &amp; Learning Paths","text":"<p>I am currently working through several structured learning paths. The Coursework section tracks notes and artefacts from:</p> <ul> <li>Google IT Automation with Python </li> <li>IBM Generative AI Engineering Professional Certificate </li> <li>Vanderbilt Prompt Engineering Specialization </li> <li>Certificates overview (completed achievements and status)  </li> </ul> <p>You\u2019ll find course-level hubs, module notes, prompt experiments, and test reflections \u2014 all focused on retention, understanding, and practical application.</p> <p>\u2192 Navigate via: <code>Coursework</code></p>"},{"location":"00_Home/#knowledge-base-tools","title":"Knowledge Base &amp; Tools","text":""},{"location":"00_Home/#knowledge-base","title":"Knowledge Base","text":"<p>A curated set of topics I want to keep coming back to:</p> <ul> <li>AI Concepts: foundations, comparisons, and mental models  </li> <li>Glossary: terms I care about and how I define them  </li> <li>Prompt Patterns: pattern-level knowledge extracted from practice  </li> <li>Reading Notes: highlights and reflections from articles and papers  </li> <li>Safety &amp; Ethics: trustworthy AI, risk thinking, and responsibility  </li> </ul> <p>\u2192 Navigate via: <code>Knowledge Base</code></p>"},{"location":"00_Home/#tools","title":"Tools","text":"<p>The Tools section documents the ecosystem I\u2019m building around my work:</p> <ul> <li>GitHub  </li> <li>JupyterLab  </li> <li>Linux notes  </li> <li>VS Code  </li> <li>Zettlr  </li> <li>marimo  </li> <li>Nextcloud  </li> </ul> <p>Each page is meant as a personal reference sheet: setup steps, commands, usage patterns, and gotchas.</p> <p>\u2192 Navigate via: <code>Tools</code></p>"},{"location":"00_Home/#tags-daily-notes","title":"Tags &amp; Daily Notes","text":"<ul> <li>Tags: a simple index for cross-cutting themes (topics that span multiple sections).  </li> <li>Daily Notes: time-stamped working notes, reflections, and scratch thinking for specific days.</li> </ul> <p>These are the most \u201calive\u201d parts of the hub \u2014 they show what I\u2019m focusing on at any given time.</p> <p>\u2192 Navigate via: <code>Tags</code> and <code>Daily Notes</code></p>"},{"location":"00_Home/#how-to-read-this-hub-for-reviewers-recruiters","title":"How to read this hub (for reviewers &amp; recruiters)","text":"<p>If you\u2019re here to understand how I work, a good path is:</p> <ol> <li>Start here (Home) to understand the structure and intent  </li> <li>Visit Prompt Engineering Portfolio Hub to see how I design and run projects  </li> <li>Explore Io Persona to see thinking about AI collaboration and system design  </li> <li>Skim Coursework to see my structured learning and test performance context  </li> <li>Dip into Knowledge Base or Tools for depth in areas that interest you  </li> </ol> <p>This hub is intentionally work-in-progress. The point is not perfection \u2014 it\u2019s to show clarity, structure, curiosity, and growth over time.</p>"},{"location":"00_Home/instructions/","title":"How to Use This Knowledge Hub","text":"<ol> <li>Start each session at [[index.md]].</li> <li>Log work and reflections in the latest daily note in <code>08_Daily_Notes/</code>.</li> <li>For portfolio work, use:</li> <li>[[../01_Projects/Prompt_Engineering_Portfolio/hub.md|Prompt Engineering Portfolio Hub]]</li> <li>For IO persona evolution, use:</li> <li>[[../02_IO_Persona/io_overview.md|IO Persona Overview]]</li> <li>For coursework, use:</li> <li>[[../04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/index.md]]</li> </ol> <p>This hub is designed to evolve with your workflow and portfolio.</p>","tags":["instructions","meta"]},{"location":"00_Home/structure/","title":"KnowledgeHub Structure","text":"<p>A hybrid overview of the CJK KnowledgeHub architecture</p> <p>The CJK KnowledgeHub is organized to balance clarity for external readers and depth for internal development. This page provides both: - a high-level map of the site, and - curated internal tree views for the most important areas of work.</p>"},{"location":"00_Home/structure/#1-home","title":"\ud83c\udfdb\ufe0f 1. Home","text":"<p>Directory: <code>00_Home/</code> </p> <p>Contains the entry points to the entire KnowledgeHub: - index.md \u2014 The landing page and overview - instructions.md \u2014 How to navigate and use the KnowledgeHub - structure.md \u2014 This site structure document  </p> <p>This section acts as the \u201cfront door\u201d for visitors and reviewers.</p>"},{"location":"00_Home/structure/#2-featured-work-projects","title":"\ud83e\udde9 2. Featured Work \u2014 Projects","text":"<p>Directory: <code>01_Projects/</code> </p> <p>This section showcases work that is most relevant to hiring managers and collaborators.</p>"},{"location":"00_Home/structure/#high-level-contents","title":"High-Level Contents","text":"<ul> <li>Prompt Engineering Portfolio Hub </li> <li>Case Studies </li> <li>Conversational AI Hub </li> <li>Portfolio Infrastructure Hub</li> </ul>"},{"location":"00_Home/structure/#curated-internal-structure","title":"Curated Internal Structure","text":"<pre><code>01_Projects/\n\u251c\u2500\u2500 Prompt_Engineering_Portfolio/\n\u2502 \u251c\u2500\u2500 hub.md\n\u2502 \u251c\u2500\u2500 backlog.md\n\u2502 \u251c\u2500\u2500 decisions.md\n\u2502 \u2514\u2500\u2500 workflow_notes.md\n\u2502\n\u251c\u2500\u2500 Case_Studies/\n\u2502 \u2514\u2500\u2500 index.md\n\u2502\n\u251c\u2500\u2500 Conversational_AI/\n\u2502 \u2514\u2500\u2500 hub.md\n\u2502\n\u2514\u2500\u2500 Portfolio_Infrastructure/\n\u2514\u2500\u2500 hub.md\n</code></pre> <p>Internal planning files (e.g., backlog, decisions, workflow notes) are stored here but not exposed in the main navigation.</p>"},{"location":"00_Home/structure/#3-io-persona-flagship-project","title":"\ud83e\udd16 3. Io Persona \u2014 Flagship Project","text":"<p>Directory: <code>02_IO_Persona/</code> </p> <p>This section documents the full evolution of Io, from early prototypes to the current multi-layered persona system.</p>"},{"location":"00_Home/structure/#high-level-contents_1","title":"High-Level Contents","text":"<ul> <li>Project Overview </li> <li>IO-I \u2014 Foundational models  </li> <li>IO-II \u2014 Persona architecture and protocols  </li> <li>IO-III \u2014 Early conceptual design for future agent systems  </li> <li>Experiments \u2014 Research, scratchpads, prototypes</li> </ul>"},{"location":"00_Home/structure/#curated-internal-structure_1","title":"Curated Internal Structure","text":"<pre><code>02_IO_Persona/\n\u251c\u2500\u2500 io_overview.md\n\u2502\n\u251c\u2500\u2500 IO-I/\n\u2502 \u251c\u2500\u2500 notes.md\n\u2502 \u251c\u2500\u2500 v1.0/blueprint.md\n\u2502 \u251c\u2500\u2500 v1.1/blueprint.md\n\u2502 \u2514\u2500\u2500 v1.2/blueprint.md\n\u2502\n\u251c\u2500\u2500 IO-II/\n\u2502 \u251c\u2500\u2500 notes.md\n\u2502 \u251c\u2500\u2500 v1.1/blueprint.md\n\u2502 \u251c\u2500\u2500 v1.2/blueprint.md\n\u2502 \u251c\u2500\u2500 v1.3/blueprint.md\n\u2502 \u2514\u2500\u2500 v1.4_dev/blueprint.md\n\u2502\n\u251c\u2500\u2500 IO-III/\n\u2502 \u251c\u2500\u2500 roadmap.md\n\u2502 \u2514\u2500\u2500 v0.1_concepts/blueprint.md\n\u2502\n\u2514\u2500\u2500 experiments/\n\u2514\u2500\u2500 scratchpad.md\n</code></pre> <p>This section represents your most complex, ambitious work. It stays fully documented for transparency, conceptual rigor, and future expansion.</p>"},{"location":"00_Home/structure/#4-workflows","title":"\ud83e\uddea 4. Workflows","text":"<p>Directory: <code>03_Workflows/</code> </p> <p>This section contains reusable systems, methodologies, and process frameworks.</p>"},{"location":"00_Home/structure/#visible-sections","title":"Visible sections","text":"<ul> <li>Code Notebooks </li> <li>Creative Workflows </li> <li>Evaluation Workflows </li> <li>Prompting Workflows </li> <li>Research Workflows</li> </ul>"},{"location":"00_Home/structure/#structure","title":"Structure","text":"<pre><code>03_Workflows/\n\u251c\u2500\u2500 Code_Notebooks/\n\u251c\u2500\u2500 Creative/\n\u251c\u2500\u2500 Evaluation/\n\u251c\u2500\u2500 Prompting/\n\u2514\u2500\u2500 Research/\n</code></pre> <p>Each directory includes its own index and serves as a modular component of your prompt engineering and AI methodology toolkit.</p>"},{"location":"00_Home/structure/#5-coursework","title":"\ud83c\udf93 5. Coursework","text":"<p>Directory: <code>04_Coursework/</code> </p> <p>This section tracks your formal learning and certifications.</p>"},{"location":"00_Home/structure/#visible-sections_1","title":"Visible sections","text":"<ul> <li>Certificates </li> <li>Google IT Automation with Python </li> <li>IBM Generative AI Engineering </li> <li>Vanderbilt Prompt Engineering Specialization</li> </ul>"},{"location":"00_Home/structure/#structure-curated","title":"Structure (curated)","text":"<pre><code>04_Coursework/\n\u251c\u2500\u2500 Certificates/\n\u251c\u2500\u2500 Google_IT_Automation_with_Python/\n\u251c\u2500\u2500 IBM_Generative_AI_Engineering_Professional_Certificate/\n\u2514\u2500\u2500 Vanderbilt_Prompt_Engineering_Specialization/\n(multiple course modules + prompt pattern references)\n</code></pre> <p>All modules, tests, prompts, and coursework files are retained for documentation integrity, but only top-level hubs appear in the nav.</p>"},{"location":"00_Home/structure/#6-knowledge-base","title":"\ud83d\udcda 6. Knowledge Base","text":"<p>Directory: <code>05_Knowledge_Base/</code> </p> <p>Centralized reference library for theory, concepts, and applied knowledge.</p>"},{"location":"00_Home/structure/#includes","title":"Includes:","text":"<ul> <li>AI Concepts </li> <li>Glossary </li> <li>Prompt Patterns Library </li> <li>Reading Notes </li> <li>Safety &amp; Ethics</li> </ul>"},{"location":"00_Home/structure/#structure_1","title":"Structure","text":"<pre><code>05_Knowledge_Base/\n\u251c\u2500\u2500 AI_Concepts/\n\u251c\u2500\u2500 Glossary.md\n\u251c\u2500\u2500 Prompt_Patterns/\n\u251c\u2500\u2500 Reading_Notes/\n\u2514\u2500\u2500 Safety_Ethics/\n</code></pre> <p>This functions as your personal \u201cAI textbook.\u201d</p>"},{"location":"00_Home/structure/#7-tools","title":"\ud83d\udee0\ufe0f 7. Tools","text":"<p>Directory: <code>06_Tools/</code> </p> <p>Documentation and workflow notes for the tools used across your projects.</p>"},{"location":"00_Home/structure/#includes_1","title":"Includes:","text":"<ul> <li>GitHub  </li> <li>JupyterLab  </li> <li>Linux Notes  </li> <li>VS Code  </li> <li>Zettlr  </li> <li>marimo  </li> <li>Nextcloud  </li> </ul>"},{"location":"00_Home/structure/#structure_2","title":"Structure","text":"<pre><code>06_Tools/\n\u251c\u2500\u2500 GitHub.md\n\u251c\u2500\u2500 JupyterLab.md\n\u251c\u2500\u2500 Linux_Notes.md\n\u251c\u2500\u2500 VS_Code.md\n\u251c\u2500\u2500 Zettlr.md\n\u251c\u2500\u2500 marimo.md\n\u2514\u2500\u2500 Nextcloud.md\n</code></pre>"},{"location":"00_Home/structure/#8-tags","title":"\ud83c\udff7\ufe0f 8. Tags","text":"<p>Directory: <code>07_Tags/</code></p> <p>Contains the tag index for cross-navigation and search organization.</p> <pre><code>07_Tags/\n\u2514\u2500\u2500 tag_index.md\n</code></pre>"},{"location":"00_Home/structure/#9-daily-notes","title":"\ud83d\udcdd 9. Daily Notes","text":"<p>Directory: <code>08_Daily_Notes/</code> A chronological log of development snapshots, reflections, and work sessions.</p> <pre><code>08_Daily_Notes/\n\u2514\u2500\u2500 YYYY-MM-DD.md\n</code></pre>"},{"location":"00_Home/structure/#summary","title":"\u2705 Summary","text":"<p>The KnowledgeHub integrates:</p> <ul> <li>Public-facing clarity for hiring managers and reviewers  </li> <li>Internal depth for your own research, engineering, and documentation  </li> <li>Versioned evolution of major projects like Io  </li> <li>Full learning trajectories across certifications and technical tracks  </li> <li>A reusable workflow ecosystem for future projects  </li> </ul> <p>It is both a portfolio and an operating system for your work.</p>"},{"location":"01_Projects/Case_Studies/","title":"Case Studies \u2014 Index","text":"<p>List and link your case studies here.</p>","tags":["case-study","portfolio"]},{"location":"01_Projects/Conversational_AI/hub/","title":"Conversational AI \u2014 Project Hub","text":"<p>Placeholder hub for future conversational and interaction design projects.</p>","tags":["conversational-ai","portfolio"]},{"location":"01_Projects/Portfolio_Infrastructure/hub/","title":"Portfolio Infrastructure \u2014 Project Hub","text":"<p>Notes and decisions about how your GitHub, wiki, and tools are organized.</p>","tags":["portfolio","infrastructure"]},{"location":"01_Projects/Prompt_Engineering_Portfolio/backlog/","title":"Backlog \u2014 Prompt Engineering Portfolio","text":"","tags":["portfolio","backlog"]},{"location":"01_Projects/Prompt_Engineering_Portfolio/backlog/#ready","title":"Ready","text":"<ul> <li>[ ] Create GitHub repo <code>prompt-engineering-portfolio</code></li> <li>[ ] Define repo README structure</li> <li>[ ] Draft 5\u201310 core prompt templates</li> <li>[ ] Sketch first workflow (content generation)</li> <li>[ ] Sketch first evaluation notebook</li> </ul>","tags":["portfolio","backlog"]},{"location":"01_Projects/Prompt_Engineering_Portfolio/backlog/#in-progress","title":"In Progress","text":"<ul> <li>[ ] </li> </ul>","tags":["portfolio","backlog"]},{"location":"01_Projects/Prompt_Engineering_Portfolio/backlog/#done","title":"Done","text":"<ul> <li>[x] Define project hub and backlog</li> </ul>","tags":["portfolio","backlog"]},{"location":"01_Projects/Prompt_Engineering_Portfolio/decisions/","title":"Decision Log \u2014 Prompt Engineering Portfolio","text":"<p>Record key decisions here.</p>","tags":["portfolio","decisions"]},{"location":"01_Projects/Prompt_Engineering_Portfolio/decisions/#decisions","title":"Decisions","text":"<ul> <li>2025-12-02 \u2014 Use <code>prompt-engineering-portfolio</code> as flagship GitHub repo name.</li> <li>2025-12-02 \u2014 Structure portfolio around prompt library, workflows, evaluation, and case studies.</li> </ul>","tags":["portfolio","decisions"]},{"location":"01_Projects/Prompt_Engineering_Portfolio/hub/","title":"Prompt Engineering Portfolio \u2014 Project Hub","text":"<p>This section of the CJK KnowledgeHub is dedicated to my work in prompt engineering. It serves as the project hub for case studies, experiments, coursework integrations, and long-term systems like the Io Persona.</p> <p>The goal of this hub is to show how I think, design, and iterate with large language models \u2013 not just final outputs.</p>"},{"location":"01_Projects/Prompt_Engineering_Portfolio/hub/#1-what-lives-in-this-portfolio","title":"1. What Lives in This Portfolio?","text":"<p>This portfolio gathers together:</p> <ul> <li>Case Studies   End-to-end explorations that highlight:</li> <li>problem framing  </li> <li>prompt design and iteration  </li> <li>reasoning and verification strategies  </li> <li> <p>outcomes and reflections  </p> </li> <li> <p>Patterns &amp; Techniques   Practical applications of prompt patterns such as:</p> </li> <li>Few-shot prompting  </li> <li>Game-play, Template, Recipe, and Meta-language patterns  </li> <li> <p>Reasoning and evaluation workflows  </p> </li> <li> <p>Systems &amp; Workflows   How I combine:</p> </li> <li>Io Persona  </li> <li>prompt patterns  </li> <li>external tools (JupyterLab, GitHub, etc.)   into repeatable workflows that can be used in real projects.</li> </ul> <p>Over time, this hub will become the main public-facing entry point to my prompt engineering work.</p>"},{"location":"01_Projects/Prompt_Engineering_Portfolio/hub/#2-structure-of-this-section","title":"2. Structure of This Section","text":"<p>The <code>Prompt_Engineering_Portfolio</code> folder is organised to support both storytelling and internal iteration:</p> <ul> <li> <p><code>hub.md</code>   \u2192 This page. High-level overview and navigation entry point.</p> </li> <li> <p><code>backlog.md</code> (internal working file)   \u2192 List of ideas, future case studies, and experiments I plan to develop.</p> </li> <li> <p><code>decisions.md</code> (internal working file)   \u2192 Design decisions, trade-offs, and rationale behind how I structure prompts, workflows, and this portfolio over time.</p> </li> <li> <p><code>workflow_notes.md</code> (internal working file)   \u2192 Notes on prompt workflows, iteration loops, evaluation setups, and experiment logs.</p> </li> </ul> <p>These internal pages are not meant as polished case studies; they show the thinking and planning that sits behind the public-facing work.</p>"},{"location":"01_Projects/Prompt_Engineering_Portfolio/hub/#3-relationship-to-vanderbilt-prompt-engineering-coursework","title":"3. Relationship to Vanderbilt Prompt Engineering Coursework","text":"<p>Many of the ideas and experiments here are grounded in the Vanderbilt Prompt Engineering Specialization (Coursera):</p> <ul> <li>Course 1 \u2014 Prompt Engineering for ChatGPT </li> <li>Course 2 \u2014 ChatGPT Advanced Data Analysis </li> <li>Course 3 \u2014 Trustworthy Generative AI</li> </ul> <p>I treat that coursework as:</p> <ul> <li>a knowledge base (patterns, frameworks, best practices), and  </li> <li>a launch pad for my own case studies, workflows, and Io Persona evolution.</li> </ul> <p>Concrete course notes, tests, and sandbox prompts live under:</p> <ul> <li><code>04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/...</code></li> </ul> <p>This hub will reference that material selectively, focusing on how I apply those concepts in real work.</p>"},{"location":"01_Projects/Prompt_Engineering_Portfolio/hub/#4-for-recruiters-collaborators-and-reviewers","title":"4. For Recruiters, Collaborators, and Reviewers","text":"<p>If you are evaluating my profile, this section is designed to demonstrate:</p> <ul> <li>Practical Prompt Engineering Skill</li> <li>clear problem decomposition  </li> <li>structured prompts and patterns  </li> <li> <p>iterative improvement instead of one-shot answers  </p> </li> <li> <p>Reasoning &amp; Verification Mindset</p> </li> <li>awareness of hallucinations and model limits  </li> <li>explicit verification steps and protocols  </li> <li> <p>use of tools (code, docs, tests) alongside language models  </p> </li> <li> <p>Systemic Thinking</p> </li> <li>connecting prompt design with Io Persona  </li> <li>designing processes, not just isolated prompts  </li> <li>building reusable workflows and documentation</li> </ul> <p>Future additions will include:</p> <ul> <li>Fully written case studies  </li> <li>Side-by-side \u201cprompt \u2192 iteration \u2192 outcome\u201d breakdowns  </li> <li>Links into Io Persona blueprints where relevant</li> </ul>"},{"location":"01_Projects/Prompt_Engineering_Portfolio/hub/#5-how-to-navigate-from-here","title":"5. How to Navigate from Here","text":"<p>Use this hub as your starting point:</p> <ul> <li>For polished narratives \u2192 go to the Case Studies section from the main navigation.  </li> <li>For a peek into the thinking behind the scenes:</li> <li><code>Backlog</code> </li> <li><code>Decisions</code> </li> <li><code>Workflow Notes</code> </li> </ul> <p>As the portfolio grows, this page will remain the anchor for everything related to Prompt Engineering in the CJK KnowledgeHub.</p>"},{"location":"01_Projects/Prompt_Engineering_Portfolio/workflow_notes/","title":"Workflow Notes \u2014 Prompt Engineering Portfolio","text":"<p>Use this file to sketch and refine workflows before turning them into formal documentation or notebooks.</p> <ul> <li>Link to final workflows in <code>03_Workflows/</code>.</li> </ul>","tags":["portfolio","workflow"]},{"location":"02_IO_Persona/io_overview/","title":"Io Persona \u2014 Flagship AI System","text":"<p>A multi-version architectural project exploring human\u2013AI collaboration, reasoning protocols, and advanced prompt engineering systems.</p> <p>The Io Persona is the centerpiece of my applied AI engineering work. It is a long-term design and research project focused on creating a structured, scalable framework for human\u2013AI interaction, blending:</p> <ul> <li>systems design  </li> <li>reasoning architecture  </li> <li>prompt engineering methodology  </li> <li>UX and cognitive workflow design  </li> <li>reproducible AI behavior across contexts  </li> </ul> <p>Io is not a \u201ccharacter.\u201d It is a modular AI operating system built through iterative versions, each introducing new capabilities, protocols, and interface patterns.</p> <p>This page provides an overview of its evolution.</p>"},{"location":"02_IO_Persona/io_overview/#io-i-foundations","title":"\ud83c\udf31 IO-I \u2014 Foundations","text":"<p>Directory: <code>02_IO_Persona/IO-I/</code> </p> <p>The IO-I generation established the fundamental concepts that the later persona systems build on.</p>"},{"location":"02_IO_Persona/io_overview/#core-achievements","title":"Core Achievements","text":"<ul> <li>Defined the first persona blueprint format, versioned and trackable.  </li> <li>Introduced interaction modes (explainer, collaborator, tutor).  </li> <li>Early experiments in prompt scaffolding and role constraints.  </li> <li>Created base documentation procedures (notes, v1.0 \u2192 v1.2 blueprints).</li> </ul>"},{"location":"02_IO_Persona/io_overview/#why-it-matters","title":"Why it matters","text":"<p>IO-I shows where the project began: early cognitive boundaries, interaction theory, and prototyping mindsets. It serves as historical context and a baseline for evaluating growth.</p>"},{"location":"02_IO_Persona/io_overview/#io-ii-systems-architecture-protocols-current-major-generation","title":"\u2699\ufe0f IO-II \u2014 Systems Architecture &amp; Protocols (Current Major Generation)","text":"<p>Directory: <code>02_IO_Persona/IO-II/</code> </p> <p>IO-II represents a major leap: the transition from persona concept \u2192 structured AI system.</p> <p>This version introduced the combined ideas of:</p> <ul> <li>Modes (Executor, Explorer, Challenger, Synthesizer, Visionary)  </li> <li>Accuracy Alignment Framework </li> <li>Drift Detection &amp; Correction Protocols </li> <li>Ambiguity Resolution Rules </li> <li>Reasoning Verification Hooks </li> <li>Triadic Metrics (Honesty, Accuracy, Candor) </li> <li>Dual-Mode Operation (Tutor + Collaborator)</li> </ul>"},{"location":"02_IO_Persona/io_overview/#what-io-ii-accomplished","title":"What IO-II accomplished","text":"<ol> <li>Codified the persona as a modular system rather than loose prompting.  </li> <li>Established a verifiable operating logic, including required questions, checks, and confirmation loops.  </li> <li>Enabled repeatable behavior across sessions, tools, and environments.  </li> <li>Supported long-term projects (Python Course, Portfolio Infrastructure, Prompt Engineering training).</li> </ol>"},{"location":"02_IO_Persona/io_overview/#why-it-matters_1","title":"Why it matters","text":"<p>Recruiters and technical reviewers see this as evidence of: - prompt engineering maturity - UX-driven system design - thinking in \u201cframeworks,\u201d not one-off prompts - engineering discipline in iteration and debugging  </p> <p>It is the strongest demonstration of your technical capability and design sophistication.</p>"},{"location":"02_IO_Persona/io_overview/#io-iii-future-agent-concepts-early-exploration","title":"\ud83d\ude80 IO-III \u2014 Future Agent Concepts (Early Exploration)","text":"<p>Directory: <code>02_IO_Persona/IO-III/</code> </p> <p>IO-III is a conceptual research track focused on future capabilities.</p>"},{"location":"02_IO_Persona/io_overview/#themes-under-exploration","title":"Themes under exploration","text":"<ul> <li>Local multi-agent orchestration  </li> <li>Hardware/sensor integration concepts  </li> <li>Memory partitions and long-term autonomy  </li> <li>Modular \u201cpersona plug-ins\u201d  </li> <li>Scalable reasoning patterns and internal tools  </li> </ul> <p>IO-III is not active. It captures forward-looking thinking and documents the long-term vision for the Io ecosystem.</p>"},{"location":"02_IO_Persona/io_overview/#why-include-it","title":"Why include it?","text":"<p>For hiring managers and technical teams, it shows:</p> <ul> <li>strategic thinking  </li> <li>ability to design beyond immediate constraints  </li> <li>systems architecture imagination  </li> <li>a roadmap mindset  </li> </ul> <p>It telegraphs leadership potential, not just practitioner skills.</p>"},{"location":"02_IO_Persona/io_overview/#experiments-research","title":"\ud83d\udd2c Experiments &amp; Research","text":"<p>Directory: <code>02_IO_Persona/experiments/</code> </p> <p>A dedicated space for:</p> <ul> <li>scratchpads  </li> <li>prototypes  </li> <li>test prompts  </li> <li>reasoning experiments  </li> <li>interface and mode variations  </li> </ul> <p>This section highlights continuous exploration and iterative improvement \u2014 a key part of your engineering identity.</p>"},{"location":"02_IO_Persona/io_overview/#summary-of-evolution","title":"\ud83e\udded Summary of Evolution","text":"Version Focus Key Contributions IO-I Foundations First persona blueprints, role modes, conceptual frameworks IO-II Architecture Protocols, verification, dual-mode operation, scalable systems IO-III Future R&amp;D Multi-agent concepts, autonomy design, vision exploration"},{"location":"02_IO_Persona/io_overview/#why-the-io-persona-is-featured-work","title":"\ud83c\udfaf Why the Io Persona is Featured Work","text":"<p>The Io Persona project is not only central to your own workflow \u2014 it is one of the most compelling demonstrations of your abilities in:</p> <ul> <li>prompt engineering  </li> <li>AI system design  </li> <li>UX architecture  </li> <li>documentation and versioning  </li> <li>conceptual and applied reasoning  </li> <li>research-oriented iteration  </li> </ul> <p>For recruiters, this project shows:</p> <ul> <li>depth  </li> <li>creativity  </li> <li>technical rigor  </li> <li>maturity of process  </li> <li>long-term thinking  </li> </ul> <p>It is your flagship because without it, the KnowledgeHub would not exist in the form it does today.</p>"},{"location":"02_IO_Persona/IO-I/notes/","title":"IO-I \u2014 Notes","text":"<p>High-level notes about IO-I persona design and behavior.</p>","tags":["io-persona","io-i"]},{"location":"02_IO_Persona/IO-II/notes/","title":"IO-II \u2014 Notes","text":"<p>High-level notes about IO-II persona evolution and versions.</p>","tags":["io-persona","io-ii"]},{"location":"02_IO_Persona/IO-III/roadmap/","title":"IO-III \u2014 Roadmap","text":"<p>High-level ideas and milestones for IO-III as a multi-agent, sensor-integrated system.</p>","tags":["io-persona","io-iii"]},{"location":"02_IO_Persona/experiments/scratchpad/","title":"IO Persona \u2014 Experiments Scratchpad","text":"<p>Use this for quick persona-related experiments before formalizing changes.</p>","tags":["io-persona","experiments"]},{"location":"03_Workflows/Code_Notebooks/","title":"Workflows \u2014 Code &amp; Notebooks","text":"<p>Index of workflows involving JupyterLab, marimo, and Python for evaluation or automation.</p>","tags":["workflow","notebooks"]},{"location":"03_Workflows/Creative/","title":"Workflows \u2014 Creative","text":"<p>Index of creative workflows (e.g., narrative design, interactive experiences, scripts, content design).</p>","tags":["workflow","creative"]},{"location":"03_Workflows/Evaluation/","title":"Workflows \u2014 Evaluation","text":"<p>Index of workflows for testing prompts, measuring quality, and detecting hallucinations.</p>","tags":["workflow","evaluation"]},{"location":"03_Workflows/Prompting/","title":"Workflows \u2014 Prompting","text":"<p>Index of prompting workflows (e.g., content generation, research assistant, evaluation prompts).</p>","tags":["workflow","prompt-engineering"]},{"location":"03_Workflows/Research/","title":"Workflows \u2014 Research","text":"<p>Index of workflows for research, long-doc analysis, and structured reading.</p>","tags":["workflow","research"]},{"location":"04_Coursework/Certificates/","title":"Certificates \u2014 Index","text":"<p>List your earned certificates and relevant details here.</p>","tags":["certificates"]},{"location":"04_Coursework/Google_IT_Automation_with_Python/","title":"Google IT Automation with Python \u2014 Index","text":"<p>Use this folder for your notes and module summaries.</p>","tags":["coursework","google","python"]},{"location":"04_Coursework/IBM_Generative_AI_Engineering_Professional_Certificate/","title":"IBM Generative AI Engineering Professional Certificate \u2014 Index","text":"<p>Use this folder for IBM course notes and integration with your portfolio.</p>","tags":["coursework","ibm","generative-ai"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/","title":"Prompt Engineering Specialization \u2014 Notes Portal","text":"<p>This site is a lightweight view of my structured notes.</p> <p>Full repository: https://github.com/CevenJKnowles/prompt-engineering-specialization</p>","tags":["PromptEngineering","AIEngineering","course_unknown","module_0","index","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/","title":"Graded Assignment 1","text":"","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#creating-your-first-prompts","title":"Creating Your First Prompts","text":"","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#1-create-a-prompt-for-a-large-language-model-such-as-chatgpt-to-describe-how-large-language-models-work-ask-at-least-three-follow-up-questions-based-on-the-output-provide-the-prompts-and-outputs-from-the-conversation-as-the-answer","title":"1. Create a prompt for a large language model, such as ChatGPT, to describe how large language models work. Ask at least three follow-up questions based on the output. Provide the prompts and outputs from the conversation as the answer.","text":"","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#answer","title":"Answer","text":"<p>Me: Can you summarise in one paragraph how large language models work?</p> <p>ChatGPT: Large language models learn statistical patterns in text by training on enormous datasets, adjusting billions of internal parameters to predict the next token in a sequence. Through this repeated prediction process, they build a layered internal representation of grammar, semantics, reasoning patterns, factual associations, and even task structures. At runtime, the model takes an input prompt, encodes it into vectors, and then generates tokens one by one\u2014each step influenced by both the prompt and its learned internal patterns\u2014allowing it to produce coherent responses, follow instructions, or solve problems without explicit programming.</p> <p>Me: Is this the same across all LLMs?</p> <p>ChatGPT: Broadly yes\u2014but with meaningful variations.</p> <p>Almost all LLMs share the same core principle: they learn by predicting the next token and adjusting internal parameters to capture patterns in language. This predictive-learning architecture (the Transformer) is the common foundation behind GPT, Claude, Gemini, LLaMA, Mistral, and most modern open-source models.</p> <p>However, they differ in important ways:</p> <ul> <li>Training data: size, diversity, quality, and recency vary widely.</li> <li>Model size and architecture tweaks: some use standard Transformers, others use mixtures-of-experts (MoE), rotary positional embeddings, or optimized attention mechanisms.</li> <li>Fine-tuning strategy: instruction tuning, reinforcement learning from human feedback (RLHF), preference optimization (DPO), or domain-specialized training can change the model\u2019s style and capabilities.</li> <li>Inference techniques: sampling strategies, caching, parallelism, and quantization differ across model families.</li> </ul> <p>So the fundamental mechanism is shared, but the capabilities, behavior, and efficiency can differ substantially depending on these design choices.</p> <p>Me: What are the differences between Transformers, MoE, rotary positional embeddings, and optimized attention mechanisms?</p> <p>ChatGPT: Here\u2019s a clean, high-resolution breakdown of the four concepts and how they differ:</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#1-transformers-the-overall-architecture","title":"1. Transformers (the overall architecture)","text":"<p>What they are:\\ The core neural architecture behind almost all modern LLMs.</p> <p>Key idea:\\ Transformers use self-attention to let every token look at every other token in the input, learning relationships across a sequence without relying on recurrence (RNNs) or convolution (CNNs).</p> <p>Why it matters:\\ This architecture scales extremely well and captures long-range dependencies in language.</p> <p>Think of it as:\\ The entire building\u2014all other items below are components or upgrades inside that building.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#2-mixture-of-experts-moe","title":"2. Mixture-of-Experts (MoE)","text":"<p>What it is:\\ A scaling technique where the model contains multiple \u201cexpert\u201d subnetworks, but only a small subset is activated per token using a gating network.</p> <p>Key idea:\\ Instead of making one huge dense model, MoE spreads capacity across many experts while keeping compute low at inference.</p> <p>Why it matters:</p> <ul> <li> <p>Higher capacity without proportional compute cost</p> </li> <li> <p>More specialization: different experts may handle different linguistic or reasoning patterns</p> </li> </ul> <p>Think of it as:\\ A neighborhood of specialists where only the right experts wake up depending on the token.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#3-rotary-positional-embeddings-rope","title":"3. Rotary Positional Embeddings (RoPE)","text":"<p>What they are:\\ A method for encoding token order into the model using rotations in a continuous vector space.</p> <p>Key idea:\\ Transformers need position info. RoPE does this efficiently and allows extrapolation to longer contexts better than older positional systems.</p> <p>Why it matters:</p> <ul> <li> <p>Enables long context windows (many current LLMs use RoPE extensions)</p> </li> <li> <p>More stable and smoother positional encoding than sinusoidal alternatives</p> </li> </ul> <p>Think of it as:\\ A mathematical compass that helps the model understand sequence order and distance.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#4-optimized-attention-mechanisms","title":"4. Optimized Attention Mechanisms","text":"<p>What they are:\\ A general category describing any improvement that makes attention faster, cheaper, or more memory-efficient.</p> <p>Examples:</p> <ul> <li> <p>FlashAttention (faster, memory-efficient exact attention)</p> </li> <li> <p>Multi-Query Attention (Mistral, GPT-4)\u2014reduces memory by sharing key/value projections</p> </li> <li> <p>Linear attention variants (for extreme long contexts)</p> </li> <li> <p>Sliding-window or blockwise attention (Gemini, Claude optimizations)</p> </li> </ul> <p>Key idea:\\ Standard attention scales with O(n\u00b2) memory/time. Optimizations reduce that cost so models can handle longer inputs or run faster.</p> <p>Why it matters:</p> <ul> <li> <p>Enables 100k\u20131M token contexts</p> </li> <li> <p>Reduces GPU requirements</p> </li> <li> <p>Improves latency</p> </li> </ul> <p>Think of it as:\\ Upgrading the engine of the Transformer so it can handle more data with less fuel.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#how-they-relate","title":"How they relate","text":"<ul> <li> <p>Transformer = the base architecture.</p> </li> <li> <p>Rotary positional embeddings = how positions are encoded inside the Transformer.</p> </li> <li> <p>Optimized attention = ways to compute attention more efficiently within the Transformer.</p> </li> <li> <p>MoE = a way to scale the Transformer by adding many specialized expert modules.</p> </li> </ul> <p>They are not competing concepts\u2014they are layers of evolution that can coexist in a single model.</p> <p>If you'd like, I can also map each method to real models (GPT-4/5, Claude, Gemini, LLaMA, Mistral), or build you a visual diagram summarizing how these components interact.</p> <p>Me: Could you give me a list of the top 5 major LLMs and which types of architecture they use?</p> <p>ChatGPT: Here\u2019s a breakdown of five major large-language-models (LLMs) and the architectures they use:</p> <p>Model   Developer   Architecture type GPT\u20114   OpenAI  Dense decoder-only Transformer (standard Transformer architecture)  newsletter.semianalysis.com +2 kafkai.com +2</p> <p>PaLM (~540B)    Google AI   Dense decoder-only Transformer (no public large-scale MoE disclosed for that version)  Wikipedia +1</p> <p>Gemini 1.5  DeepMind / Google   Transformer + Mixture-of-Experts (MoE) architecture (\u201cexpert\u201d subnetworks selectively activated)  blog.google +1</p> <p>LLaMA 4 (the latest by Meta AI) Meta AI Mixture-of-Experts (MoE) variant of the Transformer architecture (sparse routing)  AI Meta +2 Wikipedia +2</p> <p>Mixtral 8\u00d77B (open-source)  Mistral AI  Sparse mixture-of-experts Transformer: at each layer a router picks a subset of expert feed-forward networks.  arxiv.org +1</p> <p>If you like, I can extend this list to the top 10 models and include architecture details (dense vs sparse, long-context window, expert count, etc.).</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#2-create-a-prompt-for-a-large-language-model-such-as-chatgpt-that-asks-it-to-perform-an-instruction-other-than-answering-a-question-for-example-ask-chatgpt-to-create-a-meal-plan-plan-a-trip-create-a-recipe-or-help-you-diagnose-a-problem-provide-the-prompts-and-outputs-from-the-conversation-as-the-answer","title":"2. Create a prompt for a large language model, such as ChatGPT, that asks it to perform an instruction other than answering a question. For example, ask ChatGPT to create a meal plan, plan a trip, create a recipe, or help you diagnose a problem. Provide the prompts and outputs from the conversation as the answer.","text":"","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#answer_1","title":"Answer","text":"<p>Me: Can you tell me how to make the perfect espresso?</p> <p>ChatGPT: Absolutely \u2014 here\u2019s the distilled, no-nonsense version of how to pull a perfect espresso, based on what top baristas agree on. This is practical, reproducible, and tuned for taste clarity and consistency.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#the-perfect-espresso-the-core-formula","title":"The Perfect Espresso: The Core Formula","text":"","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#1-dose-the-coffee-amount","title":"1. Dose (the coffee amount)","text":"<ul> <li> <p>18\u201320 g of high-quality, freshly roasted beans</p> </li> <li> <p>Grind fresh and fine (about table-salt fine)</p> </li> <li> <p>Espresso is extremely sensitive to grind size \u2014 this is your main control dial.</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#2-distribution-tamping","title":"2. Distribution &amp; Tamping","text":"<ul> <li> <p>Shake or tap the portafilter to level the grounds</p> </li> <li> <p>Tamp with:</p> </li> <li> <p>~15\u201320 kg of pressure</p> </li> <li> <p>Perfectly even (the levelness matters more than the strength)</p> </li> </ul> <p>Goal: a uniform coffee bed that water passes through evenly.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#3-brew-ratio","title":"3. Brew Ratio","text":"<p>The gold standard:</p> <p>1:2 ratio\\ (For 18 g in \u2192 36 g out)</p> <p>This defines the balance between sweetness, acidity, and bitterness.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#4-brew-time","title":"4. Brew Time","text":"<ul> <li> <p>25\u201330 seconds, starting the moment you hit the button</p> </li> <li> <p>If it runs too fast \u2192 grind finer</p> </li> <li> <p>Too slow \u2192 grind coarser</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#5-water","title":"5. Water","text":"<ul> <li> <p>Temperature: 92\u201396\u00b0C</p> </li> <li> <p>Clean, filtered water with balanced minerals (not distilled)</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#6-shot-appearance","title":"6. Shot Appearance","text":"<p>Look for:</p> <ul> <li> <p>Steady, thick \u201cmouse tail\u201d stream</p> </li> <li> <p>Rich, even crema</p> </li> <li> <p>No blonding until the very end (pale yellow = extraction is done)</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#taste-calibration-the-secret","title":"Taste Calibration (the secret)","text":"<p>If the shot tastes sour \u2192 under-extracted \u2192 grind finer\\ If the shot tastes bitter \u2192 over-extracted \u2192 grind coarser\\ If the shot tastes hollow/thin \u2192 increase dose or reduce output\\ If the shot tastes muddy/overwhelming \u2192 decrease dose or increase output</p> <p>This is the real artistry.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#what-perfect-tastes-like","title":"What Perfect Tastes Like","text":"<p>A great espresso should be:</p> <ul> <li> <p>Sweet first</p> </li> <li> <p>Structured acidity</p> </li> <li> <p>Balanced bitterness</p> </li> <li> <p>Thick, syrupy mouthfeel</p> </li> <li> <p>Long, pleasant finish</p> </li> </ul> <p>Even a dark roast should still have clarity, not harshness.</p> <p>If you want, I can:</p> <ul> <li> <p>Give you a step-by-step ritual customized for your machine (manual, semi-auto, or fully automatic)</p> </li> <li> <p>Optimize for specific beans (light vs. dark roast)</p> </li> <li> <p>Help you troubleshoot crema, channeling, watery shots, bitter shots\u2014anything</p> </li> </ul> <p>Just tell me your setup and what beans you use.</p> <p>Me: Can you tell me the right way if I am using a Delonghi Magnifica S full automat machine with Edeka Bio Esspresso beans?</p> <p>ChatGPT: Absolutely \u2014 with a De\u2019Longhi Magnifica S and Edeka Bio Espresso beans, \u201cperfect espresso\u201d means optimising the machine\u2019s limited controls rather than chasing caf\u00e9-grade precision. Here\u2019s the right way to get the absolute best out of this specific setup.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#1-set-your-grinder-correctly-the-most-important-step","title":"1. Set Your Grinder Correctly (the most important step)","text":"<p>The Magnifica S has a built-in burr grinder with fixed steps.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#optimal-range-for-espresso","title":"Optimal range for espresso:","text":"<p>Setting 2\u20133 (counting from the finest side)</p> <p>How to adjust correctly:</p> <ul> <li> <p>Only change the grinder while the machine is grinding (to avoid damage).</p> </li> <li> <p>Reduce one step at a time \u2192 run 2\u20133 shots \u2192 taste \u2192 adjust again.</p> </li> </ul> <p>Why:\\ These machines grind a bit coarser than caf\u00e9 grinders, so you compensate by using the machine\u2019s lowest feasible grind setting.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#2-aroma-strength-setting","title":"2. Aroma (Strength) Setting","text":"<p>Use 2 or 3 beans (medium-high strength).</p> <p>This tells the machine to dose more coffee, which is crucial because automatic machines underdose by default.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#3-amount-of-water-the-espresso-volume","title":"3. Amount of Water (the espresso volume)","text":"<p>Set the espresso button to 30\u201335 ml.</p> <p>On a super-automatic machine, controlling volume is how you approximate the correct 1:2 ratio.</p> <ul> <li> <p>Less water = richer, sweeter, more syrupy</p> </li> <li> <p>More water = thinner, bitter</p> </li> </ul> <p>30\u201335 ml is the sweet spot.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#4-temperature-setting","title":"4. Temperature Setting","text":"<p>Set to HIGH.</p> <p>Why:\\ Automatic machines lose heat faster than commercial machines. High temp brings out sweetness and reduces sourness, especially with organic beans.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#5-beans-edeka-bio-espresso","title":"5. Beans: Edeka Bio Espresso","text":"<p>These beans are:</p> <ul> <li> <p>Medium-dark, a bit oily</p> </li> <li> <p>Designed for fully automatics</p> </li> <li> <p>Naturally chocolatey, mild, low acidity</p> </li> </ul> <p>What this means for tuning:</p> <ul> <li> <p>Finer grind works well</p> </li> <li> <p>Higher temperature is ideal</p> </li> <li> <p>Keep the espresso short (don\u2019t pull 60 ml singles \u2014 they go bitter fast)</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#6-maintenance-that-affects-taste","title":"6. Maintenance That Affects Taste","text":"<p>This is not optional \u2014 these machines are extremely sensitive:</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#weekly","title":"Weekly:","text":"<ul> <li> <p>Rinse brew group</p> </li> <li> <p>Clean coffee oil buildup from the chute</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#monthly","title":"Monthly:","text":"<ul> <li> <p>Use descaler</p> </li> <li> <p>Clean the grinder hopper</p> </li> <li> <p>Empty dredge + drip tray</p> </li> </ul> <p>Dirty machines = bitter, hollow, and inconsistent espresso.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#7-the-flavour-targets-for-this-setup","title":"7. The Flavour Targets for This Setup","text":"<p>With this machine + these beans, the \u201cperfect\u201d shot should taste:</p> <ul> <li> <p>Smooth</p> </li> <li> <p>Low acidity</p> </li> <li> <p>Mild bitterness, but not burnt</p> </li> <li> <p>Chocolatey with a slight nutty finish</p> </li> <li> <p>Medium body (Magnifica S can\u2019t produce caf\u00e9-level thickness)</p> </li> </ul> <p>If it tastes sour \u2192 grind finer or raise water temp\\ If it tastes bitter \u2192 grind coarser or reduce volume to 25\u201330 ml\\ If it tastes weak \u2192 increase aroma strength and reduce water volume\\ If it tastes burnt \u2192 reduce temperature to medium (rarely needed for this bean)</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#your-ideal-settings-summary","title":"Your Ideal Settings Summary","text":"<p>For De\u2019Longhi Magnifica S + Edeka Bio Espresso beans:</p> <ul> <li> <p>Grind: 2\u20133 (fine)</p> </li> <li> <p>Aroma strength: 2\u20133 beans</p> </li> <li> <p>Water volume: 30\u201335 ml</p> </li> <li> <p>Temperature: High</p> </li> <li> <p>Maintenance: Weekly clean, monthly descale</p> </li> </ul> <p>If you want, I can give you a \u201cdial-in ritual\u201d for your first three coffees that guarantees you land on the perfect flavour within 5 minutes.</p> <p>Me: Yes, please!</p> <p>ChatGPT: Perfect \u2014 here\u2019s a dial-in ritual specifically for the De\u2019Longhi Magnifica S + Edeka Bio Espresso beans, optimized to get you to the best possible espresso in three coffees or less.</p> <p>This is simple, fast, and 100% adapted to what your machine can actually control.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#the-5-minute-dial-in-ritual","title":"THE 5-MINUTE DIAL-IN RITUAL","text":"","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#before-you-start","title":"Before you start","text":"<ul> <li> <p>Make sure the machine is heated for at least 5 minutes</p> </li> <li> <p>Use fresh beans (not older than 4\u20136 weeks after roasting)</p> </li> <li> <p>Empty drip tray + grounds bin so we\u2019re not guessing incorrectly</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#shot-1-the-baseline-shot-no-changes-yet","title":"\u2615 Shot 1 \u2014 The Baseline Shot (no changes yet)","text":"","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#your-starting-settings","title":"Your starting settings:","text":"<ul> <li> <p>Grind: 3</p> </li> <li> <p>Aroma: 2 beans</p> </li> <li> <p>Volume: 30 ml</p> </li> <li> <p>Temp: High</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#pull-the-shot-and-taste","title":"Pull the shot and taste:","text":"","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#a-if-it-tastes-slightly-sour-thin-or-acidic-its-under-extracted","title":"A) If it tastes slightly sour, thin, or acidic \u2192 it\u2019s under-extracted","text":"<p>Do this on Shot 2:</p> <ul> <li> <p>Turn grinder to 2 (finer) while it\u2019s grinding</p> </li> <li> <p>Keep everything else the same</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#b-if-it-tastes-bitter-dry-or-sharp-its-over-extracted","title":"B) If it tastes bitter, dry, or sharp \u2192 it\u2019s over-extracted","text":"<p>Do this on Shot 2:</p> <ul> <li> <p>Keep grind at 3</p> </li> <li> <p>Reduce water to 25 ml</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#c-if-it-tastes-weak-or-watery-the-most-common-with-this-machine","title":"C) If it tastes weak or watery (the most common with this machine)","text":"<p>Do this on Shot 2:</p> <ul> <li> <p>Increase aroma to 3 beans</p> </li> <li> <p>Keep grind at 3</p> </li> <li> <p>Keep 30 ml water</p> </li> </ul> <p>If the shot tastes balanced, chocolatey, smooth, you already won.\\ But let\u2019s optimize further.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#shot-2-the-adjustment-shot","title":"\u2615 Shot 2 \u2014 The Adjustment Shot","text":"<p>Based on what you tasted:</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#if-you-used-finer-grind-to-2","title":"If you used finer grind (to 2):","text":"<ul> <li> <p>Pull another 30 ml shot</p> </li> <li> <p>Taste again:</p> </li> <li> <p>If more sweetness + body \u2192 perfect</p> </li> <li> <p>If bitterness appears \u2192 go back to grind 3</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#if-you-used-less-water-25-ml","title":"If you used less water (25 ml):","text":"<ul> <li> <p>Taste again:</p> </li> <li> <p>If flavours are richer + less bitter \u2192 keep 25 ml</p> </li> <li> <p>If it\u2019s too concentrated \u2192 go to 28 ml</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#if-you-increased-aroma-3-beans","title":"If you increased aroma (3 beans):","text":"<ul> <li> <p>Taste again:</p> </li> <li> <p>If crema improves + shot feels fuller \u2192 keep it</p> </li> <li> <p>If it becomes harsh \u2192 return to 2 beans</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#shot-3-final-optimization-this-locks-your-settings","title":"\u2615 Shot 3 \u2014 Final Optimization (this locks your settings)","text":"<p>This is where you secure the best combination.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#use-this-logic","title":"Use this logic:","text":"<p>If Shot 2 was nearly perfect but missing sweetness \u2192 return to grind 3 + keep 30 ml\\ If Shot 2 was tasty but slightly thin \u2192 2 beans \u2192 3 beans\\ If Shot 2 was good but slightly bitter \u2192 reduce to 28 ml\\ If Shot 2 was close but sour \u2192 ensure temp = High and grind = 2</p> <p>After Shot 3, you\u2019ll have your final profile.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#expected-final-settings-most-common-perfect-combo","title":"\ud83c\udfaf EXPECTED FINAL SETTINGS (most common perfect combo)","text":"<p>For your setup (Magnifica S + Edeka Bio Espresso beans), the 90% success profile is:</p> <ul> <li> <p>Grind: 2</p> </li> <li> <p>Aroma: 3 beans</p> </li> <li> <p>Volume: 28\u201330 ml</p> </li> <li> <p>Temperature: High</p> </li> </ul> <p>This gives:</p> <ul> <li> <p>Chocolatey notes</p> </li> <li> <p>Low acidity</p> </li> <li> <p>Clean finish</p> </li> <li> <p>Nice crema</p> </li> <li> <p>No bitterness</p> </li> <li> <p>Smooth mouthfeel</p> </li> </ul>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"04_Coursework/Vanderbilt_Prompt_Engineering_Specialization/course-1-prompt-engineering-for-chatgpt/module-1-course-introduction/tests/#if-you-want-i-can-help-you-diagnose-the-taste-of-your-first-real-shot","title":"If you want, I can help you diagnose the taste of your first real shot","text":"<p>If you describe what Shot 1 tasted like, I\u2019ll tell you exactly which path to take on Shot 2 and Shot 3 \u2014 no guessing.</p>","tags":["PromptEngineering","AIEngineering","prompt-engineering-for-chatgpt","course_1","module_1","tests","Vanderbilt","Coursera"]},{"location":"05_Knowledge_Base/Glossary/","title":"Glossary","text":"<p>Key terms and definitions used across your knowledge hub.</p>","tags":["glossary","knowledge-base"]},{"location":"05_Knowledge_Base/AI_Concepts/","title":"AI Concepts \u2014 Index","text":"<p>Core AI concepts, definitions, and explanations.</p>","tags":["ai-concept","knowledge-base"]},{"location":"05_Knowledge_Base/Prompt_Patterns/","title":"Prompt Patterns \u2014 Index","text":"<p>Catalog of prompt patterns and usage examples.</p>","tags":["prompt-pattern","knowledge-base"]},{"location":"05_Knowledge_Base/Reading_Notes/","title":"Reading Notes \u2014 Index","text":"<p>Notes from papers, articles, and books.</p>","tags":["reading","knowledge-base"]},{"location":"05_Knowledge_Base/Safety_Ethics/","title":"AI Safety &amp; Ethics \u2014 Index","text":"<p>Notes and frameworks related to trustworthy generative AI.</p>","tags":["safety","ethics","knowledge-base"]},{"location":"06_Tools/GitHub/","title":"GitHub","text":"<p>Notes on how you use GitHub for your portfolio and coursework repositories.</p>","tags":["tool","github"]},{"location":"06_Tools/JupyterLab/","title":"JupyterLab","text":"<p>Notes on how you use JupyterLab for evaluation and experimentation.</p>","tags":["tool","jupyterlab"]},{"location":"06_Tools/Linux_Notes/","title":"Linux Notes","text":"<p>Linux commands, tricks, and system notes relevant to your workflow.</p>","tags":["tool","linux"]},{"location":"06_Tools/Nextcloud/","title":"Nextcloud","text":"<p>Notes on how you use Nextcloud for tasks, deadlines, and project coordination.</p>","tags":["tool","nextcloud"]},{"location":"06_Tools/VS_Code/","title":"VS Code","text":"<p>Notes on how you use VS Code for code and repo management.</p>","tags":["tool","vscode"]},{"location":"06_Tools/Zettlr/","title":"Zettlr","text":"<p>Notes on how you use Zettlr as your wiki and knowledge hub editor.</p>","tags":["tool","zettlr"]},{"location":"06_Tools/marimo/","title":"marimo","text":"<p>Notes on how you use marimo notebooks for interactive, polished workflows.</p>","tags":["tool","marimo"]},{"location":"07_Tags/tag_index/","title":"Tags \u2014 Index","text":"<p>Suggested tag taxonomy:</p>","tags":["tags"]},{"location":"07_Tags/tag_index/#portfolio","title":"portfolio","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#prompt-engineering","title":"prompt-engineering","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#workflow","title":"workflow","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#case-study","title":"case-study","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#coursework","title":"coursework","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#io-persona","title":"io-persona","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#python","title":"python","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#jupyter","title":"jupyter","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#marimo","title":"marimo","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#ai-concept","title":"ai-concept","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#prompt-pattern","title":"prompt-pattern","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#evaluation","title":"evaluation","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#safety","title":"safety","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#ethics","title":"ethics","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#resource","title":"resource","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#todo","title":"todo","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#reference","title":"reference","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#idea","title":"idea","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#reflection","title":"reflection","text":"","tags":["tags"]},{"location":"07_Tags/tag_index/#decision","title":"decision","text":"","tags":["tags"]},{"location":"08_Daily_Notes/2025-12-02/","title":"Daily Note \u2014 2025-12-02","text":"","tags":["daily","reflection","todo"]},{"location":"08_Daily_Notes/2025-12-02/#plan","title":"Plan","text":"","tags":["daily","reflection","todo"]},{"location":"08_Daily_Notes/2025-12-02/#work-log","title":"Work Log","text":"","tags":["daily","reflection","todo"]},{"location":"08_Daily_Notes/2025-12-02/#reflections","title":"Reflections","text":"","tags":["daily","reflection","todo"]}]}